{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Title hyperlinks\n",
    "title_links = pd.read_csv(\"Data/soc-redditHyperlinks-title.tsv\",'\\t')\n",
    "## Body hyperlinks\n",
    "body_links = pd.read_csv(\"Data/soc-redditHyperlinks-body.tsv\",'\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rddtgaming</td>\n",
       "      <td>rddtrust</td>\n",
       "      <td>1u4pzzs</td>\n",
       "      <td>2013-12-31 16:39:18</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0,23.0,0.76,0.0,0.44,0.12,0.12,4.0,4.0,0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xboxone</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1u4tmfs</td>\n",
       "      <td>2013-12-31 17:59:11</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ps4</td>\n",
       "      <td>battlefield_4</td>\n",
       "      <td>1u4tmos</td>\n",
       "      <td>2013-12-31 17:59:40</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>leangains</td>\n",
       "      <td>1u50xfs</td>\n",
       "      <td>2013-12-31 19:01:56</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0,43.0,0.775510204082,0.0,0.265306122449,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>lifeprotips</td>\n",
       "      <td>1u51nps</td>\n",
       "      <td>2013-12-31 21:02:28</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0,14.0,0.785714285714,0.0,0.428571428571,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "0         rddtgaming         rddtrust  1u4pzzs  2013-12-31 16:39:18   \n",
       "1            xboxone    battlefield_4  1u4tmfs  2013-12-31 17:59:11   \n",
       "2                ps4    battlefield_4  1u4tmos  2013-12-31 17:59:40   \n",
       "3  fitnesscirclejerk        leangains  1u50xfs  2013-12-31 19:01:56   \n",
       "4  fitnesscirclejerk      lifeprotips  1u51nps  2013-12-31 21:02:28   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \n",
       "0               1  25.0,23.0,0.76,0.0,0.44,0.12,0.12,4.0,4.0,0.0,...  \n",
       "1               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...  \n",
       "2               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,...  \n",
       "3               1  49.0,43.0,0.775510204082,0.0,0.265306122449,0....  \n",
       "4               1  14.0,14.0,0.785714285714,0.0,0.428571428571,0....  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>teamredditteams</td>\n",
       "      <td>1u4nrps</td>\n",
       "      <td>2013-12-31 16:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0,298.0,0.75652173913,0.0173913043478,0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>theredlion</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1u4qkd</td>\n",
       "      <td>2013-12-31 18:18:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>101.0,98.0,0.742574257426,0.019801980198,0.049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>inlandempire</td>\n",
       "      <td>bikela</td>\n",
       "      <td>1u4qlzs</td>\n",
       "      <td>2014-01-01 14:54:35</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0,85.0,0.752941176471,0.0235294117647,0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1u4sjvs</td>\n",
       "      <td>2013-12-31 17:37:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.0,949.0,0.772241992883,0.0017793594306,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>playmygame</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>1u4w5ss</td>\n",
       "      <td>2014-01-01 02:51:13</td>\n",
       "      <td>1</td>\n",
       "      <td>715.0,622.0,0.777622377622,0.00699300699301,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "0  leagueoflegends  teamredditteams  1u4nrps  2013-12-31 16:39:58   \n",
       "1       theredlion           soccer   1u4qkd  2013-12-31 18:18:37   \n",
       "2     inlandempire           bikela  1u4qlzs  2014-01-01 14:54:35   \n",
       "3              nfl              cfb  1u4sjvs  2013-12-31 17:37:55   \n",
       "4       playmygame          gamedev  1u4w5ss  2014-01-01 02:51:13   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \n",
       "0               1  345.0,298.0,0.75652173913,0.0173913043478,0.08...  \n",
       "1              -1  101.0,98.0,0.742574257426,0.019801980198,0.049...  \n",
       "2               1  85.0,85.0,0.752941176471,0.0235294117647,0.082...  \n",
       "3               1  1124.0,949.0,0.772241992883,0.0017793594306,0....  \n",
       "4               1  715.0,622.0,0.777622377622,0.00699300699301,0....  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the data is presented is as follows\n",
    "\n",
    "- SOURCE_SUBREDDIT: the subreddit where the link originates\n",
    "- TARGET_SUBREDDIT: the subreddit where the link ends\n",
    "- POST_ID: the post in the source subreddit that starts the link\n",
    "- TIMESTAMP: time time of the post\n",
    "- POST_LABEL: label indicating if the source post is explicitly negative towards the target post. The value is -1 if the source is negative towards the target, and 1 if it is neutral or positive. The label is created using crowd-sourcing and training a text based classifier, and is better than simple sentiment analysis of the posts. Please see the reference paper for details.\n",
    "- POST_PROPERTIES: a vector representing the text properties of the source post, listed as a list of comma separated numbers. The vector elements are the following:\n",
    "    1. Number of characters\n",
    "    2. Number of characters without counting white space\n",
    "    3. Fraction of alphabetical characters\n",
    "    4. Fraction of digits\n",
    "    5. Fraction of uppercase characters\n",
    "    6. Fraction of white spaces\n",
    "    7. Fraction of special characters, such as comma, exclamation mark, etc.\n",
    "    8. Number of words\n",
    "    9. Number of unique works\n",
    "    10. Number of long words (at least 6 characters)\n",
    "    11. Average word length\n",
    "    12. Number of unique stopwords\n",
    "    13. Fraction of stopwords\n",
    "    14. Number of sentences\n",
    "    15. Number of long sentences (at least 10 words)\n",
    "    16. Average number of characters per sentence\n",
    "    17. Average number of words per sentence\n",
    "    18. Automated readability index\n",
    "    19. Positive sentiment calculated by VADER\n",
    "    20. Negative sentiment calculated by VADER\n",
    "    21. Compound sentiment calculated by VADER\n",
    "    22. LIWC_Funct\n",
    "    23. LIWC_Pronoun\n",
    "    24. LIWC_Ppron\n",
    "    25. LIWC_I\n",
    "    26. LIWC_We\n",
    "    27. LIWC_You\n",
    "    28. LIWC_SheHe\n",
    "    29. LIWC_They\n",
    "    30. LIWC_Ipron\n",
    "    31. LIWC_Article\n",
    "    32. LIWC_Verbs\n",
    "    33. LIWC_AuxVb\n",
    "    34. LIWC_Past\n",
    "    35. LIWC_Present\n",
    "    36. LIWC_Future\n",
    "    37. LIWC_Adverbs\n",
    "    38. LIWC_Prep\n",
    "    39. LIWC_Conj\n",
    "    40. LIWC_Negate\n",
    "    41. LIWC_Quant\n",
    "    42. LIWC_Numbers\n",
    "    43. LIWC_Swear\n",
    "    44. LIWC_Social\n",
    "    45. LIWC_Family\n",
    "    46. LIWC_Friends\n",
    "    47. LIWC_Humans\n",
    "    48. LIWC_Affect\n",
    "    49. LIWC_Posemo\n",
    "    50. LIWC_Negemo\n",
    "    51. LIWC_Anx\n",
    "    52. LIWC_Anger\n",
    "    53. LIWC_Sad\n",
    "    54. LIWC_CogMech\n",
    "    55. LIWC_Insight\n",
    "    56. LIWC_Cause\n",
    "    57. LIWC_Discrep\n",
    "    58. LIWC_Tentat\n",
    "    59. LIWC_Certain\n",
    "    60. LIWC_Inhib\n",
    "    61. LIWC_Incl\n",
    "    62. LIWC_Excl\n",
    "    63. LIWC_Percept\n",
    "    64. LIWC_See\n",
    "    65. LIWC_Hear\n",
    "    66. LIWC_Feel\n",
    "    67. LIWC_Bio\n",
    "    68. LIWC_Body\n",
    "    69. LIWC_Health\n",
    "    70. LIWC_Sexual\n",
    "    71. LIWC_Ingest\n",
    "    72. LIWC_Relativ\n",
    "    73. LIWC_Motion\n",
    "    74. LIWC_Space\n",
    "    75. LIWC_Time\n",
    "    76. LIWC_Work\n",
    "    77. LIWC_Achiev\n",
    "    78. LIWC_Leisure\n",
    "    79. LIWC_Home\n",
    "    80. LIWC_Money\n",
    "    81. LIWC_Relig\n",
    "    82. LIWC_Death\n",
    "    83. LIWC_Assent\n",
    "    84. LIWC_Dissent\n",
    "    85. LIWC_Nonflu\n",
    "    86. LIWC_Filler    \n",
    "\n",
    "###  Note that POST_PROPERTIES were constructed in order to assign a sign (-1 or 1) to the directed link betweet the SOURCE_SUBREDDIT and TARGET_SUBREDDIT.\n",
    "### These signs are contained in POST_LABEL. Thus, we will basically need only those three features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Title links :\n",
      "The number of links in the title links dataset:\t 571927\n",
      "The number of unique source subreddits: \t 43695\n",
      "the set of all subreddits in the title dataset:\t 54075\n",
      "====================\n",
      "====================\n",
      "Body links :\n",
      "The number of links in the body links dataset: \t 286561\n",
      "The number of unique source subreddits : \t 27863\n",
      "the set of all subreddits in the body dataset :\t 35776\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "## Drop unwanted features \n",
    "title_links = title_links[[\"SOURCE_SUBREDDIT\",\"TARGET_SUBREDDIT\",\"LINK_SENTIMENT\",\"TIMESTAMP\"]]\n",
    "body_links = body_links[[\"SOURCE_SUBREDDIT\",\"TARGET_SUBREDDIT\",\"LINK_SENTIMENT\",\"TIMESTAMP\"]]\n",
    "\n",
    "\n",
    "## Print some characteristics for Title links\n",
    "print(20*'=')\n",
    "print('Title links :')\n",
    "title_source_subreddits = title_links.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in the title links dataset:\\t {len(title_source_subreddits)}')\n",
    "title_source_set = set(title_source_subreddits)\n",
    "print(f'The number of unique source subreddits: \\t {len(title_source_set)}')\n",
    "title_subreddits = set(title_links.SOURCE_SUBREDDIT.values.tolist() + title_links.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits in the title dataset:\\t {len(title_subreddits)}')\n",
    "print(20*'=')\n",
    "\n",
    "## Print some characteristics for Body links\n",
    "print(20*'=')\n",
    "print(\"Body links :\")\n",
    "body_source_subreddits = body_links.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in the body links dataset: \\t {len(body_source_subreddits)}')\n",
    "body_source_set = set(body_source_subreddits)\n",
    "print(f'The number of unique source subreddits : \\t {len(body_source_set)}')\n",
    "body_subreddits = set(body_links.SOURCE_SUBREDDIT.values.tolist() + body_links.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits in the body dataset :\\t {len(body_subreddits)}')\n",
    "print(20*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subreddit links :\n",
      "The number of links in all data: \t 858488\n",
      "The number of unique source subreddits:  55863\n",
      "the set of all subreddits :\t\t 67180\n"
     ]
    }
   ],
   "source": [
    "## Here we concatenate the both dataframes to create a unique dataset of connexions between subreddits.\n",
    "Data = pd.concat([title_links,body_links])\n",
    "Data = Data.rename({\"LINK_SENTIMENT\":\"Sign\",\"TIMESTAMP\":'Date'},axis=1)\n",
    "print(\"All subreddit links :\")\n",
    "source_subreddits = Data.SOURCE_SUBREDDIT.values.tolist()\n",
    "print(f'The number of links in all data: \\t {len(source_subreddits)}')\n",
    "source_set = set(source_subreddits)\n",
    "print(f'The number of unique source subreddits:  {len(source_set)}')\n",
    "subreddits = set(Data.SOURCE_SUBREDDIT.values.tolist() + Data.TARGET_SUBREDDIT.values.tolist())\n",
    "print(f'the set of all subreddits :\\t\\t {len(subreddits)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 776278 positive links and 82210 negative links\n",
      "REDDIT : Pourcentage of (+)edges is 90.4% and pourcentage of (-)edges is 9.6%\n"
     ]
    }
   ],
   "source": [
    "## Let's see the number and pourcentages of positive and negatives links\n",
    "number_pos_links = Data.where(Data.Sign==1).count()[0]\n",
    "number_neg_links = Data.where(Data.Sign==-1).count()[0]\n",
    "print(f'There is {number_pos_links} positive links and {number_neg_links} negative links')\n",
    "\n",
    "print(f'REDDIT : Pourcentage of (+)edges is {round(number_pos_links*100/len(Data),1)}% and pourcentage of (-)edges is {round(number_neg_links*100/len(Data),1)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing these pourcentages to the ones of Epinions or Slashdot datasets, We can see that Reddit has a lot less negatives links than the others. We can state (hypothetize ?) that the interactions betweet subreddits are mostly positive and that negative links are especially for conflicts rather than just negative opinion/vote and of course, conflicts are much less likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a graph of subreddits links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDDIT:    Nodes = 67180  Edges = 339643\n",
      "REDDIT : Pourcentage of (+)edges is 92.5% and pourcentage of (-)edges is 7.5%\n"
     ]
    }
   ],
   "source": [
    "complete_graph = nx.from_pandas_edgelist(Data,source='SOURCE_SUBREDDIT', target=\"TARGET_SUBREDDIT\", edge_attr = [\"Sign\",\"Date\"],create_using=nx.DiGraph)\n",
    "\n",
    "nbr_nodes = complete_graph.number_of_nodes()\n",
    "nbr_edges = complete_graph.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes,\" Edges =\",nbr_edges)\n",
    "\n",
    "sum_of_pos = sum(1 if w[\"Sign\"]==1 else 0 for (_,_,w) in complete_graph.edges(data=True))\n",
    "sum_of_neg = sum(1 if w[\"Sign\"]==-1 else 0 for (_,_,w) in complete_graph.edges(data=True))\n",
    "pourc_of_pos = round(100 *sum_of_pos/nbr_edges,1)\n",
    "pourc_of_neg = round(100 *sum_of_neg/nbr_edges,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos, neg= pourc_of_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this way of creating the graph led us to dropping an huge number of edges (from 858488 to 339643) while keeping the same number of nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since our dataset contains a lot of duplicates edges (Some of those edges may be all positive or all negative or a combination of positive and negative signs). Creating our directed graph directly from those edges, will ommit these duplicates and will take into account only their last occurences. Thus , it will take only the last sign of the link betweet those two subreddits. This will alter our perspectives since in a case where all links but the LAST ONE , between subreddit A and subreddit B were negative, this generated graph will take only the positive link and we will be dropping very important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and generate a multiple directed graph (MultiDiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDDIT:    Nodes = 67180  Edges = 858488\n",
      "REDDIT : Pourcentage of (+)edges is 90.4% and pourcentage of (-)edges is 9.6%\n"
     ]
    }
   ],
   "source": [
    "complete_multi_graph = nx.from_pandas_edgelist(Data,source='SOURCE_SUBREDDIT', target=\"TARGET_SUBREDDIT\", edge_attr = [\"Sign\",'Date'],create_using=nx.MultiDiGraph)\n",
    "\n",
    "nbr_nodes = complete_multi_graph.number_of_nodes()\n",
    "nbr_edges = complete_multi_graph.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes,\" Edges =\",nbr_edges)\n",
    "\n",
    "sum_of_pos = sum(1 if w[\"Sign\"]==1 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "sum_of_neg = sum(1 if w[\"Sign\"]==-1 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "pourc_of_pos = round(100 *sum_of_pos/nbr_edges,1)\n",
    "pourc_of_neg = round(100 *sum_of_neg/nbr_edges,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos, neg= pourc_of_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see now that this graph contains more informations about the data than the other one; It complete and have all edges and nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since one of our objectives is to compare the similarities and differences between the individuals datasets (Epinions, slashdot and wikipedia) and the communities dataset (Reddit) , apart from this methode of creating a multiple edges directed graph, we decides to generate another graph that , for each multiple signed edges between same two nodes, will create a single edge with the mean of all those signs as unique weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we group by (source,target) but instead of keeping all weights, we sum them into one weight\n",
    "groupedBySource_Target_mean = Data.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT']).Sign.apply(lambda x: np.mean(x)).to_frame()\n",
    "## The groupby function makes the pair (source,target) as index.\n",
    "# To construct the graph, we need to have list of all sources , targets and signs in a dataframe \n",
    "listed_source = [ elem[0] for elem in groupedBySource_Target_mean.index]\n",
    "listed_target = [ elem[1] for elem in groupedBySource_Target_mean.index]\n",
    "listed_sign = [ elem[0] for elem in groupedBySource_Target_mean.values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We groupby the data using pairs (source,target) and collect all link signs between same pair in one attribute (a dictionary)\n",
    "groupedBySource_Target_pair = Data.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT']).Date.apply(lambda x: list(x)).to_frame()\n",
    "groupedBySource_Target_pair.Date = groupedBySource_Target_pair.Date.apply(lambda x: x[len(x)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mean = pd.DataFrame({\"source\":listed_source,\"target\":listed_target,\"Sign\":listed_sign,'Date':groupedBySource_Target_pair.Date.apply(lambda x: x[:10].replace('-','/'))}).reset_index().drop(columns=[\"SOURCE_SUBREDDIT\",\"TARGET_SUBREDDIT\"])\n",
    "\n",
    "graph_mean = nx.from_pandas_edgelist(data_mean,source='source', target=\"target\", edge_attr = [\"Sign\",'Date'],create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This meaned graph contains 339643 signed edges.\n",
      "The number of edges which mean is equal to 1 is 298473\n",
      "The number of edges which mean is equal to -1 is 18104\n"
     ]
    }
   ],
   "source": [
    "print(f'This meaned graph contains {len(data_mean)} signed edges.')\n",
    "print(f'The number of edges which mean is equal to 1 is {len(data_mean[data_mean.Sign==1])}')\n",
    "print(f'The number of edges which mean is equal to -1 is {len(data_mean[data_mean.Sign==-1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the mean sign of the edges by majority 1 or -1. \n",
    "### From this, we decided to define \"FRIENDS Communities\" by the communities which only have **multiple** (ie : >=2) positive edges. and \"ENEMIES communities\" by the communities which only have **multiple** (ie : >=2) negative edges.\n",
    "\n",
    "for this, we need to isolate the communities that have multiple edges between them : ie: we can't consider that two communities are enemies just by having only one negative link between them. so we just keep multiple linked communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We groupby the data using pairs (source,target) and collect all link signs between same pair in one attribute (a dictionary)\n",
    "groupedBySource_Target_pair = Data.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT']).LINK_SENTIMENT.apply(lambda x: list(x)).to_frame()\n",
    "groupedBySource_Target_pair.LINK_SENTIMENT = groupedBySource_Target_pair.LINK_SENTIMENT.apply(lambda x: dict(zip(np.arange(len(x)), x)))\n",
    "## The groupby function makes the pair (source,target) as index.\n",
    "# To construct the graph, we need to have list of all sources , targets and signs in a dataframe \n",
    "listed_source_dict = [ elem[0] for elem in groupedBySource_Target_pair.index]\n",
    "listed_target_dict = [ elem[1] for elem in groupedBySource_Target_pair.index]\n",
    "listed_sign_dict = [ elem[0] for elem in groupedBySource_Target_pair.values ]\n",
    "\n",
    "data_dict_df = pd.DataFrame({\"source\":listed_source_dict,\"target\":listed_target_dict,\"sign\":listed_sign_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices =[]\n",
    "for i,elem in zip(range(len(data_dict_df.sign.values)),data_dict_df.sign.values):\n",
    "    if len(elem)>=4: indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_multiple_edges = data_dict_df.loc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100daysofketo</td>\n",
       "      <td>keto</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>30daystosortmylifeout</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>howtonotgiveafuck</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieaweek</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieclub</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339586</td>\n",
       "      <td>zorceror44</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339596</td>\n",
       "      <td>zreviews</td>\n",
       "      <td>audiophile</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339634</td>\n",
       "      <td>zylooxwrites</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339635</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339637</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>summonerschool</td>\n",
       "      <td>{0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36966 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                 target  \\\n",
       "22           100daysofketo                   keto   \n",
       "25      100daysofrejection  30daystosortmylifeout   \n",
       "27      100daysofrejection      howtonotgiveafuck   \n",
       "30        100movies365days             movieaweek   \n",
       "31        100movies365days              movieclub   \n",
       "...                    ...                    ...   \n",
       "339586          zorceror44         writingprompts   \n",
       "339596            zreviews             audiophile   \n",
       "339634        zylooxwrites         writingprompts   \n",
       "339635           zyramains        leagueoflegends   \n",
       "339637           zyramains         summonerschool   \n",
       "\n",
       "                                                     sign  \n",
       "22                         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}  \n",
       "25                         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1}  \n",
       "27      {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...  \n",
       "30       {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1}  \n",
       "31                   {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1}  \n",
       "...                                                   ...  \n",
       "339586                           {0: 1, 1: 1, 2: 1, 3: 1}  \n",
       "339596                           {0: 1, 1: 1, 2: 1, 3: 1}  \n",
       "339634                           {0: 1, 1: 1, 2: 1, 3: 1}  \n",
       "339635  {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: ...  \n",
       "339637         {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}  \n",
       "\n",
       "[36966 rows x 3 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_multiple_edges.re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9760"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(data_multiple_edges.source.unique()) or set(data_multiple_edges.target.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_edges_meaned_data = data_mean.loc[indices].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100daysofketo</td>\n",
       "      <td>keto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/05/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>30daystosortmylifeout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>howtonotgiveafuck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/11/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieaweek</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieclub</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339586</td>\n",
       "      <td>zorceror44</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/08/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339596</td>\n",
       "      <td>zreviews</td>\n",
       "      <td>audiophile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/06/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339634</td>\n",
       "      <td>zylooxwrites</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/11/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339635</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339637</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>summonerschool</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/06/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36966 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                 target  Sign        Date\n",
       "22           100daysofketo                   keto   1.0  2016/05/07\n",
       "25      100daysofrejection  30daystosortmylifeout   1.0  2015/12/01\n",
       "27      100daysofrejection      howtonotgiveafuck   1.0  2015/11/14\n",
       "30        100movies365days             movieaweek   1.0  2014/07/12\n",
       "31        100movies365days              movieclub   1.0  2014/07/12\n",
       "...                    ...                    ...   ...         ...\n",
       "339586          zorceror44         writingprompts   1.0  2016/08/25\n",
       "339596            zreviews             audiophile   1.0  2016/06/25\n",
       "339634        zylooxwrites         writingprompts   1.0  2015/11/05\n",
       "339635           zyramains        leagueoflegends   1.0  2016/11/16\n",
       "339637           zyramains         summonerschool   1.0  2016/06/17\n",
       "\n",
       "[36966 rows x 4 columns]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_edges_meaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4929</td>\n",
       "      <td>againsthatesubreddits</td>\n",
       "      <td>4chan</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017/04/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5009</td>\n",
       "      <td>againsthatesubreddits</td>\n",
       "      <td>gender_critical</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017/02/08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>againsthatesubreddits</td>\n",
       "      <td>undelete</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2015/09/11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5392</td>\n",
       "      <td>againstmensrights</td>\n",
       "      <td>atheism</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016/12/06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5487</td>\n",
       "      <td>againstmensrights</td>\n",
       "      <td>publicfreakout</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017/02/15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315074</td>\n",
       "      <td>twoxchromosomes</td>\n",
       "      <td>confession</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2015/06/29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321818</td>\n",
       "      <td>uvajerk</td>\n",
       "      <td>uva</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017/01/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327721</td>\n",
       "      <td>watchredditdie</td>\n",
       "      <td>news</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016/12/02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329205</td>\n",
       "      <td>wehraboosinaction</td>\n",
       "      <td>historyporn</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016/12/21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334395</td>\n",
       "      <td>worstof</td>\n",
       "      <td>prorevenge</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2017/03/02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       source           target  Sign        Date\n",
       "4929    againsthatesubreddits            4chan  -1.0  2017/04/05\n",
       "5009    againsthatesubreddits  gender_critical  -1.0  2017/02/08\n",
       "5150    againsthatesubreddits         undelete  -1.0  2015/09/11\n",
       "5392        againstmensrights          atheism  -1.0  2016/12/06\n",
       "5487        againstmensrights   publicfreakout  -1.0  2017/02/15\n",
       "...                       ...              ...   ...         ...\n",
       "315074        twoxchromosomes       confession  -1.0  2015/06/29\n",
       "321818                uvajerk              uva  -1.0  2017/01/01\n",
       "327721         watchredditdie             news  -1.0  2016/12/02\n",
       "329205      wehraboosinaction      historyporn  -1.0  2016/12/21\n",
       "334395                worstof       prorevenge  -1.0  2017/03/02\n",
       "\n",
       "[119 rows x 4 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enemies_df = multiple_edges_meaned_data[multiple_edges_meaned_data.Sign==-1].copy()\n",
    "enemies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'harpersrecession',\n",
       " 'mongolianhatewatch',\n",
       " 'postamericanhistory',\n",
       " 'shittyokcupid2',\n",
       " 'the_iowa'}"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(enemies_df.source.unique()) -  (set(Data[Data.Sign==1].SOURCE_SUBREDDIT.unique()) or set(Data[Data.Sign==1].TARGET_SUBREDDIT.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see here that there is subreddits that initiates only NEGATIVE links to other subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>312910</td>\n",
       "      <td>harpersrecession</td>\n",
       "      <td>canada</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-01-19 11:58:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313125</td>\n",
       "      <td>harpersrecession</td>\n",
       "      <td>soylent</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-01-19 20:33:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313622</td>\n",
       "      <td>harpersrecession</td>\n",
       "      <td>canada</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-01-20 18:21:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314301</td>\n",
       "      <td>harpersrecession</td>\n",
       "      <td>canada</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-01-21 19:01:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SOURCE_SUBREDDIT TARGET_SUBREDDIT  Sign                 Date\n",
       "312910  harpersrecession           canada    -1  2016-01-19 11:58:51\n",
       "313125  harpersrecession          soylent    -1  2016-01-19 20:33:37\n",
       "313622  harpersrecession           canada    -1  2016-01-20 18:21:02\n",
       "314301  harpersrecession           canada    -1  2016-01-21 19:01:54"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data.SOURCE_SUBREDDIT==\"harpersrecession\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>235198</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>european</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-08-30 07:52:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238207</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>european</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-08-30 07:52:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242467</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>european</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-08-30 07:52:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273497</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>european</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-11-02 17:55:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277230</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>topmindsofreddit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-11-02 22:14:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277237</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>againsthatesubreddits</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-11-02 22:14:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279497</td>\n",
       "      <td>mongolianhatewatch</td>\n",
       "      <td>european</td>\n",
       "      <td>-1</td>\n",
       "      <td>2015-11-02 22:14:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOURCE_SUBREDDIT       TARGET_SUBREDDIT  Sign                 Date\n",
       "235198  mongolianhatewatch               european    -1  2015-08-30 07:52:35\n",
       "238207  mongolianhatewatch               european    -1  2015-08-30 07:52:35\n",
       "242467  mongolianhatewatch               european    -1  2015-08-30 07:52:35\n",
       "273497  mongolianhatewatch               european    -1  2015-11-02 17:55:45\n",
       "277230  mongolianhatewatch       topmindsofreddit    -1  2015-11-02 22:14:04\n",
       "277237  mongolianhatewatch  againsthatesubreddits    -1  2015-11-02 22:14:04\n",
       "279497  mongolianhatewatch               european    -1  2015-11-02 22:14:04"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data.SOURCE_SUBREDDIT==\"mongolianhatewatch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>333089</td>\n",
       "      <td>postamericanhistory</td>\n",
       "      <td>economics</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-02-23 03:53:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337940</td>\n",
       "      <td>postamericanhistory</td>\n",
       "      <td>economics</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-03-19 14:03:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340739</td>\n",
       "      <td>postamericanhistory</td>\n",
       "      <td>economics</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-03-19 14:03:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SOURCE_SUBREDDIT TARGET_SUBREDDIT  Sign                 Date\n",
       "333089  postamericanhistory        economics    -1  2016-02-23 03:53:08\n",
       "337940  postamericanhistory        economics    -1  2016-03-19 14:03:18\n",
       "340739  postamericanhistory        economics    -1  2016-03-19 14:03:18"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data.SOURCE_SUBREDDIT==\"postamericanhistory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>467277</td>\n",
       "      <td>shittyokcupid2</td>\n",
       "      <td>okcupid</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11-09 03:58:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472275</td>\n",
       "      <td>shittyokcupid2</td>\n",
       "      <td>okcupid</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11-17 08:19:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475311</td>\n",
       "      <td>shittyokcupid2</td>\n",
       "      <td>okcupid</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-11-24 06:57:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SOURCE_SUBREDDIT TARGET_SUBREDDIT  Sign                 Date\n",
       "467277   shittyokcupid2          okcupid    -1  2016-11-09 03:58:04\n",
       "472275   shittyokcupid2          okcupid    -1  2016-11-17 08:19:39\n",
       "475311   shittyokcupid2          okcupid    -1  2016-11-24 06:57:51"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data.SOURCE_SUBREDDIT==\"shittyokcupid2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>543601</td>\n",
       "      <td>the_iowa</td>\n",
       "      <td>iowa</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-03-18 06:16:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544359</td>\n",
       "      <td>the_iowa</td>\n",
       "      <td>iowa</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-03-19 06:18:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>546131</td>\n",
       "      <td>the_iowa</td>\n",
       "      <td>iowa</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-03-22 09:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547385</td>\n",
       "      <td>the_iowa</td>\n",
       "      <td>iowa</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-03-24 10:27:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SOURCE_SUBREDDIT TARGET_SUBREDDIT  Sign                 Date\n",
       "543601         the_iowa             iowa    -1  2017-03-18 06:16:24\n",
       "544359         the_iowa             iowa    -1  2017-03-19 06:18:24\n",
       "546131         the_iowa             iowa    -1  2017-03-22 09:52:00\n",
       "547385         the_iowa             iowa    -1  2017-03-24 10:27:57"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[Data.SOURCE_SUBREDDIT==\"the_iowa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's generally a repetitive negative links in a maximum of one month period of time so we may say that it's a conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>07scape</td>\n",
       "      <td>osrstranscripts</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0magick</td>\n",
       "      <td>occult</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0x02</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0x10c</td>\n",
       "      <td>techcompliant</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100daysofketo</td>\n",
       "      <td>keto</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339622</td>\n",
       "      <td>zurich</td>\n",
       "      <td>switzerland</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339629</td>\n",
       "      <td>zxspectrum</td>\n",
       "      <td>retrogaming</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339634</td>\n",
       "      <td>zylooxwrites</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339635</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339637</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>summonerschool</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               source           target  sign\n",
       "1             07scape  osrstranscripts   1.0\n",
       "6             0magick           occult   1.0\n",
       "10               0x02   writingprompts   1.0\n",
       "12              0x10c    techcompliant   1.0\n",
       "22      100daysofketo             keto   1.0\n",
       "...               ...              ...   ...\n",
       "339622         zurich      switzerland   1.0\n",
       "339629     zxspectrum      retrogaming   1.0\n",
       "339634   zylooxwrites   writingprompts   1.0\n",
       "339635      zyramains  leagueoflegends   1.0\n",
       "339637      zyramains   summonerschool   1.0\n",
       "\n",
       "[70072 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends_df = multiple_edges_meaned_data[multiple_edges_meaned_data.sign==1].copy()\n",
    "friends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of source subreddits from which originates the friendships : 18460\n",
      "number of source subreddits from which originates the conflicts : 433\n"
     ]
    }
   ],
   "source": [
    "print(f'number of source subreddits from which originates the friendships : {len(friends_df.source.unique())}')\n",
    "print(f'number of source subreddits from which originates the conflicts : {len(enemies_df.source.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bouhmid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "indices_source_enemies = []\n",
    "for i,elem in zip(range(len(Data)),Data.SOURCE_SUBREDDIT.values):\n",
    "    if elem in enemies_df.source.unique() : indices_source_enemies.append(i)\n",
    "        \n",
    "edges_originated_from_enemies_source = Data.loc[indices_source_enemies].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>nfl</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>shitstatistssay</td>\n",
       "      <td>foodforthought</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>casualiama</td>\n",
       "      <td>teenagers</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>metaphotography</td>\n",
       "      <td>photography</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>sjsucks</td>\n",
       "      <td>truechristian</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571866</td>\n",
       "      <td>badwomensanatomy</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571891</td>\n",
       "      <td>peoplewhosayheck</td>\n",
       "      <td>sex</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571908</td>\n",
       "      <td>peoplewhosayheck</td>\n",
       "      <td>divorce</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571912</td>\n",
       "      <td>conspiracy</td>\n",
       "      <td>truereddit</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571919</td>\n",
       "      <td>anarcho_capitalism</td>\n",
       "      <td>truereddit</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47372 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOURCE_SUBREDDIT TARGET_SUBREDDIT  LINK_SENTIMENT\n",
       "16          subredditdrama              nfl            -1.0\n",
       "52         shitstatistssay   foodforthought            -1.0\n",
       "53              casualiama        teenagers            -1.0\n",
       "68         metaphotography      photography            -1.0\n",
       "89                 sjsucks    truechristian            -1.0\n",
       "...                    ...              ...             ...\n",
       "571866    badwomensanatomy        askreddit            -1.0\n",
       "571891    peoplewhosayheck              sex            -1.0\n",
       "571908    peoplewhosayheck          divorce            -1.0\n",
       "571912          conspiracy       truereddit            -1.0\n",
       "571919  anarcho_capitalism       truereddit            -1.0\n",
       "\n",
       "[47372 rows x 3 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_originated_from_enemies_source=edges_originated_from_enemies_source.dropna()\n",
    "negative_edges_originated_from_enemies_source = edges_originated_from_enemies_source[edges_originated_from_enemies_source.LINK_SENTIMENT==-1]\n",
    "negative_edges_originated_from_enemies_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>nfl</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>libertyworldproblems</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>shitstatistssay</td>\n",
       "      <td>foodforthought</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>childfree</td>\n",
       "      <td>adviceanimals</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>levantinewar</td>\n",
       "      <td>worldpolitics</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286475</td>\n",
       "      <td>badpolitics</td>\n",
       "      <td>bannedfromthe_donald</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286491</td>\n",
       "      <td>tipofmytongue</td>\n",
       "      <td>deathcore</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286501</td>\n",
       "      <td>soundcloud</td>\n",
       "      <td>procss</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286523</td>\n",
       "      <td>enoughtrumpspam</td>\n",
       "      <td>humansbeingbros</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286554</td>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>funny</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SOURCE_SUBREDDIT      TARGET_SUBREDDIT  LINK_SENTIMENT\n",
       "16            subredditdrama                   nfl              -1\n",
       "20      libertyworldproblems               bitcoin              -1\n",
       "52           shitstatistssay        foodforthought              -1\n",
       "69                 childfree         adviceanimals              -1\n",
       "80              levantinewar         worldpolitics              -1\n",
       "...                      ...                   ...             ...\n",
       "286475           badpolitics  bannedfromthe_donald              -1\n",
       "286491         tipofmytongue             deathcore              -1\n",
       "286501            soundcloud                procss              -1\n",
       "286523       enoughtrumpspam       humansbeingbros              -1\n",
       "286554        subredditdrama                 funny              -1\n",
       "\n",
       "[82210 rows x 3 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_negative_signs = Data[Data.LINK_SENTIMENT==-1].copy()\n",
    "all_negative_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8698"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_negative_signs.SOURCE_SUBREDDIT.unique()) or set(all_negative_signs.TARGET_SUBREDDIT.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we compute the pourcentage of negative edges that originated from the set of source subreddits that led to more than 2 conflicts comparing to all negative links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.623160199489114"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * len(negative_edges_originated_from_enemies_source) / len(all_negative_signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we compute the pourcentage of source subreddits that led to more than 3 conflicts comparing to the set of all source subreddits from which originated a negative link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.978155897907565"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * len(enemies_df.source.unique()) / len(all_negative_signs.SOURCE_SUBREDDIT.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i,elem in zip(range(len(all_negative_signs)),all_negative_signs.SOURCE_SUBREDDIT.values):\n",
    "    if elem in set(enemies_df.source.unique()):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bouhmid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "negative_links_originated_from_enemies_df = all_negative_signs.loc[indices].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we compute the pourcentage of negative links originated from subreddits with more than 2 conflicts comparing to the set of all negative links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.54725702469286"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*len(negative_links_originated_from_enemies_df)/len(all_negative_signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "for i,source,target in zip(range(len(Data)),Data.SOURCE_SUBREDDIT.values, Data.TARGET_SUBREDDIT.values):\n",
    "    if (source in enemies_df.source.unique() or target in enemies_df.source.unique()):\n",
    "        indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bouhmid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>leangains</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>fitnesscirclejerk</td>\n",
       "      <td>lifeprotips</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>playmygame</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>bestoftldr</td>\n",
       "      <td>tifu</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571914</td>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>alpinism</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571919</td>\n",
       "      <td>anarcho_capitalism</td>\n",
       "      <td>truereddit</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571920</td>\n",
       "      <td>peoplewhosayheck</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571923</td>\n",
       "      <td>peoplewhosayheck</td>\n",
       "      <td>spiderman</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>571926</td>\n",
       "      <td>shitpoliticssays</td>\n",
       "      <td>politicaldiscussion</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOURCE_SUBREDDIT     TARGET_SUBREDDIT  LINK_SENTIMENT\n",
       "3        fitnesscirclejerk            leangains             1.0\n",
       "3                      nfl                  cfb             1.0\n",
       "4        fitnesscirclejerk          lifeprotips             1.0\n",
       "4               playmygame              gamedev             1.0\n",
       "7               bestoftldr                 tifu             1.0\n",
       "...                    ...                  ...             ...\n",
       "571914      subredditdrama             alpinism             1.0\n",
       "571919  anarcho_capitalism           truereddit            -1.0\n",
       "571920    peoplewhosayheck             dfsports             1.0\n",
       "571923    peoplewhosayheck            spiderman             1.0\n",
       "571926    shitpoliticssays  politicaldiscussion             1.0\n",
       "\n",
       "[333740 rows x 3 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_sourceORtarget_sourceConfilcts = Data.loc[indices].dropna()\n",
    "links_sourceORtarget_sourceConfilcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for elem in set(all_negative_signs.SOURCE_SUBREDDIT.unique()):\n",
    "    if elem in set(all_negative_signs.TARGET_SUBREDDIT.unique()):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.2819038859508"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*len(set(all_negative_signs.SOURCE_SUBREDDIT.unique()) and set(all_negative_signs.TARGET_SUBREDDIT.unique())) / len(set(all_negative_signs.SOURCE_SUBREDDIT.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We cay say that if a subreddit initiated a negative link to another subreddit, it will be implicated at 76% in a conflict as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.570234323255105"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*len(set(all_negative_signs.SOURCE_SUBREDDIT.unique()) or set(all_negative_signs.TARGET_SUBREDDIT.unique())) / len(set(Data.SOURCE_SUBREDDIT.unique()) or set(Data.TARGET_SUBREDDIT.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can say that from 15.5% of the nodes originates all the conflicts between subreddit communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's take a look at the triads in the two different graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_wanted_triads(graph):\n",
    "    triads = nx.triadic_census(graph)\n",
    "    total_triads = triads['030T']+triads['030C']\n",
    "    total_triads= total_triads+(2*(triads['120U']+triads['120D']+triads['120C']))\n",
    "    total_triads=total_triads+(4*triads['210'])+(8*triads['300'])\n",
    "    return total_triads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_multigraph_triads = compute_count_wanted_triads(complete_multi_graph)\n",
    "total_meanedgraph_triads = compute_count_wanted_triads(graph_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "MEANED WEIGHTS DIRECTED GRAPH\n",
      "REDDIT:    Nodes = 67180  Edges = 339643\n",
      "REDDIT : Pourcentage of (+)edges is 92.6% and pourcentage of (-)edges is 5.7%\n",
      "====================\n",
      "MULTI EDGED DIRECTED GRAPH\n",
      "REDDIT:    Nodes = 67180  Edges = 858488\n",
      "REDDIT : Pourcentage of (+)edges is 90.4% and pourcentage of (-)edges is 9.6%\n"
     ]
    }
   ],
   "source": [
    "print(20*'=')\n",
    "print('MEANED WEIGHTS DIRECTED GRAPH')\n",
    "nbr_nodes_mean = graph_mean.number_of_nodes()\n",
    "nbr_edges_mean = graph_mean.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes_mean,\" Edges =\",nbr_edges_mean)\n",
    "\n",
    "\n",
    "sum_of_pos_mean = sum(1 if w[\"sign\"]>0 else 0 for (_,_,w) in graph_mean.edges(data=True))\n",
    "sum_of_neg_mean = sum(1 if w[\"sign\"]<0 else 0 for (_,_,w) in graph_mean.edges(data=True))\n",
    "pourc_of_pos_mean = round(100 *sum_of_pos_mean/nbr_edges_mean,1)\n",
    "pourc_of_neg_mean = round(100 *sum_of_neg_mean/nbr_edges_mean,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos_mean, neg= pourc_of_neg_mean))\n",
    "\n",
    "print(20*'=')\n",
    "print('MULTI EDGED DIRECTED GRAPH')\n",
    "nbr_nodes_multi_graph = complete_multi_graph.number_of_nodes()\n",
    "nbr_edges_multi_graph = complete_multi_graph.number_of_edges()\n",
    "print(\"REDDIT:    Nodes =\",nbr_nodes_multi_graph,\" Edges =\",nbr_edges_multi_graph)\n",
    "\n",
    "\n",
    "sum_of_pos_multi_graph = sum(1 if w[\"LINK_SENTIMENT\"]>0 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "sum_of_neg_multi_graph = sum(1 if w[\"LINK_SENTIMENT\"]<0 else 0 for (_,_,w) in complete_multi_graph.edges(data=True))\n",
    "pourc_of_pos_multi_graph = round(100 *sum_of_pos_multi_graph/nbr_edges_multi_graph,1)\n",
    "pourc_of_neg_multi_graph = round(100 *sum_of_neg_multi_graph/nbr_edges_multi_graph,1)\n",
    "print(\"REDDIT : Pourcentage of (+)edges is {pos}% and pourcentage of (-)edges is {neg}%\".format(pos = pourc_of_pos_multi_graph, neg= pourc_of_neg_multi_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MultiGraph</th>\n",
       "      <th>meaned_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Nodes</td>\n",
       "      <td>67,180</td>\n",
       "      <td>67,180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Edges</td>\n",
       "      <td>858,488</td>\n",
       "      <td>339,643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>+ edges</td>\n",
       "      <td>90.4%</td>\n",
       "      <td>92.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>- edges</td>\n",
       "      <td>9.6%</td>\n",
       "      <td>5.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Triads</td>\n",
       "      <td>4,077,337</td>\n",
       "      <td>4,077,337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MultiGraph meaned_weights\n",
       "Nodes       67,180         67,180\n",
       "Edges      858,488        339,643\n",
       "+ edges      90.4%          92.6%\n",
       "- edges       9.6%           5.7%\n",
       "Triads   4,077,337      4,077,337"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = pd.DataFrame(columns=[\"MultiGraph\",\"meaned_weights\"])\n",
    "output_df=output_df.append(pd.DataFrame([[\"{:,}\".format(nbr_nodes_multi_graph),\"{:,}\".format(nbr_nodes_mean)]],columns=[\"MultiGraph\",\"meaned_weights\"],index= {\"Nodes\"}))\n",
    "output_df=output_df.append(pd.DataFrame([[\"{:,}\".format(nbr_edges_multi_graph),\"{:,}\".format(nbr_edges_mean)]],columns=[\"MultiGraph\",\"meaned_weights\"],index= {\"Edges\"}))\n",
    "output_df=output_df.append(pd.DataFrame([[str(pourc_of_pos_multi_graph)+'%',str(pourc_of_pos_mean)+'%']],columns=[\"MultiGraph\",\"meaned_weights\"],index={\"+ edges\"}))\n",
    "output_df=output_df.append(pd.DataFrame([[str(pourc_of_neg_multi_graph)+\"%\",str(pourc_of_neg_mean)+'%']],columns=[\"MultiGraph\",\"meaned_weights\"],index={\"- edges\"}))\n",
    "output_df=output_df.append(pd.DataFrame([[\"{:,}\".format(total_multigraph_triads),\"{:,}\".format(total_meanedgraph_triads)]],columns=[\"MultiGraph\",\"meaned_weights\"],index={\"Triads\"}))\n",
    "output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will generate both the predictions of status with respect to the generative and receptive surprise , and the predictions of structural balance for EPINIONS dataset and compare its results with the results of REDDIT dataset. We will also create visualizations for our datastory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper function used to parse wikipedia data\n",
    "\n",
    "def custom_parsing(path):\n",
    "    ## Initializing everything before parsing\n",
    "    \n",
    "    result_list = []\n",
    "\n",
    "    to_node = None\n",
    "    from_node = None\n",
    "    sign = None\n",
    "\n",
    "    ## Opening the file\n",
    "    ## Chose encoding=\"iso8859_16\" as simple \"UTF-8\" gave me errors\n",
    "    with open(path, 'r', encoding=\"iso8859_16\") as f:\n",
    "        \n",
    "        ## For each line ... \n",
    "        for line in f:\n",
    "            ## Split the line by \" \"\n",
    "            splitted = line.split()\n",
    "\n",
    "            ## If empty line, continue\n",
    "            if(len(splitted) == 0):\n",
    "                continue\n",
    "\n",
    "            ## If this is a \"U\" line ...\n",
    "            elif(splitted[0] == 'U'):\n",
    "                ## Take the id of the nominated user\n",
    "                to_node = int(splitted[1])\n",
    "\n",
    "            ## If this is a \"V\" line ...\n",
    "            elif(splitted[0] == 'V'):\n",
    "                ## Take the sign of the vote\n",
    "                sign = int(splitted[1])\n",
    "                \n",
    "                ## Take the id of voter\n",
    "                from_node = int(splitted[2])\n",
    "                \n",
    "                date = splitted[3]\n",
    "                date = date.replace('-', '/')\n",
    "                \n",
    "                ## If the vote was neutral, don't take it (continue)\n",
    "                ## Else store the line in the intermediary list\n",
    "                if(sign == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    result_list.append([from_node, to_node, sign, date])\n",
    "            \n",
    "            ## If this is any other kind of line, continue\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    ## Converting the intermediary list into a dataframe and name columns correctly\n",
    "    result_df = pd.DataFrame(result_list, columns=['FromNodeId', 'ToNodeId', 'Sign', 'Date'])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data and sorting\n",
    "\n",
    "epinions_path = \"Data/user_rating.txt\"\n",
    "# epinions_path = \"data/soc-sign-epinions.txt\"\n",
    "\n",
    "epinions_df = pd.read_csv(epinions_path, sep=\"\\t\", header=None, \n",
    "                          comment=\"#\", names=['FromNodeId', 'ToNodeId', 'Sign', 'Date'])\n",
    "epinions_df = epinions_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)\n",
    "\n",
    "slashdot_df = pd.read_csv(\"data/soc-sign-Slashdot090221.txt\", sep=\"\\t\", header=None, \n",
    "                          comment=\"#\", names=['FromNodeId', 'ToNodeId', 'Sign'])\n",
    "slashdot_df = slashdot_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)\n",
    "\n",
    "wikipedia_df = custom_parsing(\"data/wikiElec.ElecBs3.txt\")\n",
    "wikipedia_df = wikipedia_df.sort_values(by=[\"FromNodeId\", \"ToNodeId\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "epinions_graph = nx.from_pandas_edgelist(epinions_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                         edge_attr=[\"Sign\", \"Date\"], create_using=nx.DiGraph)\n",
    "\n",
    "slashdot_graph = nx.from_pandas_edgelist(slashdot_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                         edge_attr=\"Sign\", create_using=nx.DiGraph)\n",
    "\n",
    "wikipedia_graph = nx.from_pandas_edgelist(wikipedia_df, source=\"FromNodeId\", target=\"ToNodeId\", \n",
    "                                          edge_attr=[\"Sign\", \"Date\"], create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_LINKS_TYPES = {\n",
    "    tuple(sorted([('vw', 1), ('wu', 1)])) : 't1',\n",
    "    tuple(sorted([('vw', 1), ('wu', -1)])) : 't2',\n",
    "    tuple(sorted([('vw', 1), ('uw', 1)])) : 't3',\n",
    "    tuple(sorted([('vw', 1), ('uw', -1)])) : 't4',\n",
    "    tuple(sorted([('vw', -1), ('wu', 1)])) : 't5',\n",
    "    tuple(sorted([('vw', -1), ('wu', -1)])) : 't6',\n",
    "    tuple(sorted([('vw', -1), ('uw', 1)])) : 't7',\n",
    "    tuple(sorted([('vw', -1), ('uw', -1)])) : 't8', \n",
    "    tuple(sorted([('wv', 1), ('wu', 1)])) : 't9',\n",
    "    tuple(sorted([('wv', 1), ('wu', -1)])) : 't10',\n",
    "    tuple(sorted([('wv', 1), ('uw', 1)])) : 't11',\n",
    "    tuple(sorted([('wv', 1), ('uw', -1)])) : 't12',\n",
    "    tuple(sorted([('wv', -1), ('wu', 1)])) : 't13',\n",
    "    tuple(sorted([('wv', -1), ('wu', -1)])) : 't14',\n",
    "    tuple(sorted([('wv', -1), ('uw', 1)])) : 't15',\n",
    "    tuple(sorted([('wv', -1), ('uw', -1)])) : 't16',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_links_census(graph):\n",
    "    census = {\n",
    "        f't{i}': {\n",
    "            '+': 0,\n",
    "            '-': 0\n",
    "    } for i in range(1, 17)}\n",
    "    \n",
    "    census_edges = {\n",
    "        f't{i}' : [] for i in range(1, 17)\n",
    "    }\n",
    "    \n",
    "    c_links_names = [f't{i}' for i in range(1, 17)]\n",
    "    \n",
    "    census = pd.DataFrame(0, index = pd.Index(c_links_names), columns = ['+', '-']) \n",
    "    \n",
    "    for v in graph:\n",
    "        vnbrs = set(graph.succ[v])\n",
    "        \n",
    "        for u in vnbrs:\n",
    "            neighbors_all = {\n",
    "                ('wv', 'wu'): (set(graph.pred[v]) & set(graph.pred[u])) - {u, v},\n",
    "                ('wv', 'uw'): (set(graph.pred[v]) & set(graph.succ[u])) - {u, v},\n",
    "                ('vw', 'wu'): (vnbrs & set(graph.pred[u])) - {u, v},\n",
    "                ('vw', 'uw'): (vnbrs & set(graph.succ[u])) - {u, v}\n",
    "            }\n",
    "            \n",
    "            for key, neighbors in neighbors_all.items():\n",
    "                for w in neighbors:\n",
    "                    mapping = {\n",
    "                            'wv': (w, v),\n",
    "                            'vw': (v, w),\n",
    "                            'wu': (w, u),\n",
    "                            'uw': (u, w)\n",
    "                        }\n",
    "                    \n",
    "                    edge_1 = mapping[key[0]]\n",
    "                    edge_2 = mapping[key[1]]\n",
    "                    \n",
    "                    if(graph[v][u]['Date'] > graph[edge_1[0]][edge_1[1]]['Date'] and \n",
    "                       graph[v][u]['Date'] > graph[edge_2[0]][edge_2[1]]['Date']):\n",
    "\n",
    "                        c_link_index = []\n",
    "\n",
    "                        sign_edge_1 = graph[edge_1[0]][edge_1[1]]['Sign']\n",
    "                        sign_edge_2 = graph[edge_2[0]][edge_2[1]]['Sign']\n",
    "\n",
    "                        c_link_index.append((key[0], sign_edge_1))\n",
    "                        c_link_index.append((key[1], sign_edge_2))\n",
    "\n",
    "                        c_link_type = C_LINKS_TYPES[tuple(sorted(c_link_index))]\n",
    "\n",
    "                        vu_sign = graph[v][u]['Sign']\n",
    "\n",
    "                        sign_idx = '+' if vu_sign == 1 else '-'\n",
    "                        \n",
    "#                         not_allowed.add(tuple(sorted([v, u, w])))\n",
    "\n",
    "                        census.loc[c_link_type][sign_idx] += 1\n",
    "                        census_edges[c_link_type].append((v, u))\n",
    "                    \n",
    "    return census, census_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_baseline(graph, list_of_c_links, gen_or_rec):\n",
    "    \n",
    "    if(gen_or_rec != 'generative' and gen_or_rec != 'receptive'):\n",
    "        raise ValueError('Impossible value for gen_or_rec argument !')\n",
    "    \n",
    "    sum_of_baselines = 0\n",
    "    \n",
    "    if(gen_or_rec == 'generative'):\n",
    "        computed_baseline = {needed_node: None for (needed_node, useless_node) in list_of_c_links}\n",
    "    else:\n",
    "        computed_baseline = {needed_node: None for (useless_node, needed_node) in list_of_c_links}\n",
    "\n",
    "    for c_link in list_of_c_links:\n",
    "        \n",
    "        baseline = 0\n",
    "        \n",
    "        if(gen_or_rec == 'generative'):\n",
    "            v = c_link[0]\n",
    "            succ = graph.succ[v]\n",
    "\n",
    "            if(computed_baseline[v] is None):\n",
    "                list_of_edges = [(v, successor) for successor in succ]\n",
    "                list_of_positive_edges = [\n",
    "                    (v, successor) for successor in succ if graph[v][successor]['Sign'] == 1\n",
    "                ]\n",
    "                \n",
    "                total_edges = len(list_of_edges)\n",
    "                total_positive_edges = len(list_of_positive_edges)\n",
    "                \n",
    "                baseline = total_positive_edges/total_edges\n",
    "                \n",
    "                computed_baseline[v] = baseline\n",
    "            else:\n",
    "                baseline = computed_baseline[v]\n",
    "            \n",
    "        else:\n",
    "            u = c_link[1]\n",
    "            pred = graph.pred[u]\n",
    "            \n",
    "            if(computed_baseline[u] is None):\n",
    "                list_of_edges = [(predecessor, u) for predecessor in pred]\n",
    "                list_of_positive_edges = [\n",
    "                    (predecessor, u) for predecessor in pred if graph[predecessor][u]['Sign'] == 1\n",
    "                ]\n",
    "                \n",
    "                total_edges = len(list_of_edges)\n",
    "                total_positive_edges = len(list_of_positive_edges)\n",
    "                \n",
    "                baseline = total_positive_edges/total_edges\n",
    "                \n",
    "                computed_baseline[u] = baseline\n",
    "            else:\n",
    "                baseline = computed_baseline[u]\n",
    "        \n",
    "        sum_of_baselines += baseline\n",
    "        \n",
    "    return sum_of_baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_B_g = [1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1]\n",
    "PRED_B_r = [1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, -1, -1, 1, -1, 1]\n",
    "PRED_S_g = [1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1]\n",
    "PRED_S_r = [1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1]\n",
    "\n",
    "def build_predictions(c_link_census, edges_per_c_link, graph):\n",
    "    predictions = c_link_census\n",
    "    predictions['count'] = predictions['+'] + predictions['-']\n",
    "    predictions['p(+)'] = predictions['+'] / predictions['count']\n",
    "    \n",
    "    c_links_names = [key for key in edges_per_c_link.keys()]\n",
    "    baselines = pd.DataFrame(index = pd.Index(c_links_names), columns = ['generative', 'receptive'])\n",
    "    \n",
    "    for c_link_type in edges_per_c_link.keys():    \n",
    "        list_of_c_links = list(edges_per_c_link[c_link_type])\n",
    "\n",
    "        print(80 * '=')\n",
    "        print(c_link_type)\n",
    "        print('Beginning generative baseline ...')\n",
    "\n",
    "        baselines.loc[c_link_type]['generative'] = compute_baseline(graph, list_of_c_links, 'generative')\n",
    "\n",
    "        print('Generative baseline finished !')\n",
    "        print('Beginning receptive baseline ...')\n",
    "\n",
    "        baselines.loc[c_link_type]['receptive'] = compute_baseline(graph, list_of_c_links, 'receptive')\n",
    "\n",
    "        print('Receptive baseline finished !')\n",
    "        print(80 * '=')\n",
    "    \n",
    "    baselines = baselines.astype(float)\n",
    "    predictions = pd.concat([predictions, baselines], axis=1)\n",
    "    \n",
    "    predictions['s_g'] = predictions['count']*predictions['p(+)'] - predictions['generative']\n",
    "    predictions['s_g'] = predictions['s_g'] / np.sqrt(predictions['generative'] * (1 - (predictions['generative']/predictions['count'])))\n",
    "\n",
    "    predictions['s_r'] = predictions['count']*predictions['p(+)'] - predictions['receptive']\n",
    "    predictions['s_r'] = predictions['s_r'] / np.sqrt(predictions['receptive'] * (1 - (predictions['receptive']/predictions['count'])))\n",
    "    \n",
    "    predictions['pred_B_g'] = PRED_B_g\n",
    "    predictions['pred_B_r'] = PRED_B_r\n",
    "    predictions['pred_S_g'] = PRED_S_g\n",
    "    predictions['pred_S_r'] = PRED_S_r\n",
    "    \n",
    "    predictions['B_g'] = predictions['pred_B_g'] * predictions['s_g'] > 0 \n",
    "    predictions['B_r'] = predictions['pred_B_r'] * predictions['s_r'] > 0\n",
    "    predictions['S_g'] = predictions['pred_S_g'] * predictions['s_g'] > 0\n",
    "    predictions['S_r'] = predictions['pred_S_r'] * predictions['s_r'] > 0\n",
    "    \n",
    "    final_df = predictions[['count', 'p(+)', 's_g', 's_r', 'B_g', 'B_r', 'S_g', 'S_r']]\n",
    "    \n",
    "    total_series = [final_df['count'].sum(), np.nan, np.nan, np.nan, \n",
    "                    final_df['B_g'].sum(), final_df['B_r'].sum(), final_df['S_g'].sum(), final_df['S_r'].sum()]\n",
    "    total_series = pd.Series(total_series, name='total', index=pd.Index(final_df.columns))\n",
    "    total_series = total_series.to_frame().transpose()\n",
    "    \n",
    "    final_df = pd.concat([final_df, total_series], axis=0)\n",
    "    \n",
    "    final_df['count'] = final_df['count'].astype(int)\n",
    "    final_df['p(+)'] = round(final_df['p(+)'], 3)\n",
    "    final_df['s_g'] = round(final_df['s_g'], 1)\n",
    "    final_df['s_r'] = round(final_df['s_r'], 1)\n",
    "    final_df['B_g'] = final_df['B_g'].astype(int)\n",
    "    final_df['B_r'] = final_df['B_r'].astype(int)\n",
    "    final_df['S_g'] = final_df['S_g'].astype(int)\n",
    "    final_df['S_r'] = final_df['S_r'].astype(int)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_link_census_epinions, edges_per_c_link_epinions = c_links_census(epinions_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_link_census_wikipedia, edges_per_c_link_wikipedia = c_links_census(wikipedia_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "t1\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t2\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t3\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t4\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t5\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t6\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t7\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t8\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t9\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t10\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t11\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t12\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t13\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t14\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t15\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t16\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t1\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t2\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t3\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t4\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t5\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t6\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t7\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t8\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t9\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t10\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t11\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t12\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t13\n",
      "Beginning generative baseline ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t14\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t15\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t16\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictions_epinions = build_predictions(c_link_census_epinions, edges_per_c_link_epinions, epinions_graph)\n",
    "predictions_wikipedia = build_predictions(c_link_census_wikipedia, edges_per_c_link_wikipedia, wikipedia_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "      <th>s_g</th>\n",
       "      <th>s_r</th>\n",
       "      <th>B_g</th>\n",
       "      <th>B_r</th>\n",
       "      <th>S_g</th>\n",
       "      <th>S_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>t1</td>\n",
       "      <td>1047479</td>\n",
       "      <td>0.950</td>\n",
       "      <td>316.7</td>\n",
       "      <td>58.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2</td>\n",
       "      <td>102593</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-149.2</td>\n",
       "      <td>-56.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t3</td>\n",
       "      <td>1120362</td>\n",
       "      <td>0.934</td>\n",
       "      <td>295.6</td>\n",
       "      <td>51.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t4</td>\n",
       "      <td>64495</td>\n",
       "      <td>0.773</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-58.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t5</td>\n",
       "      <td>125029</td>\n",
       "      <td>0.417</td>\n",
       "      <td>87.7</td>\n",
       "      <td>-555.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t6</td>\n",
       "      <td>24099</td>\n",
       "      <td>0.401</td>\n",
       "      <td>16.6</td>\n",
       "      <td>-111.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t7</td>\n",
       "      <td>90981</td>\n",
       "      <td>0.288</td>\n",
       "      <td>10.1</td>\n",
       "      <td>-473.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t8</td>\n",
       "      <td>116592</td>\n",
       "      <td>0.692</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-223.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t9</td>\n",
       "      <td>1345595</td>\n",
       "      <td>0.887</td>\n",
       "      <td>416.3</td>\n",
       "      <td>-197.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t10</td>\n",
       "      <td>80520</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-134.1</td>\n",
       "      <td>-105.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t11</td>\n",
       "      <td>797374</td>\n",
       "      <td>0.872</td>\n",
       "      <td>284.0</td>\n",
       "      <td>-125.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t12</td>\n",
       "      <td>87261</td>\n",
       "      <td>0.706</td>\n",
       "      <td>17.1</td>\n",
       "      <td>-141.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t13</td>\n",
       "      <td>56565</td>\n",
       "      <td>0.736</td>\n",
       "      <td>30.2</td>\n",
       "      <td>-168.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t14</td>\n",
       "      <td>59431</td>\n",
       "      <td>0.741</td>\n",
       "      <td>24.7</td>\n",
       "      <td>-22.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t15</td>\n",
       "      <td>72134</td>\n",
       "      <td>0.739</td>\n",
       "      <td>23.2</td>\n",
       "      <td>-136.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t16</td>\n",
       "      <td>16232</td>\n",
       "      <td>0.710</td>\n",
       "      <td>25.2</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td>5206742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count   p(+)    s_g    s_r  B_g  B_r  S_g  S_r\n",
       "t1     1047479  0.950  316.7   58.6    1    1    1    1\n",
       "t2      102593  0.492 -149.2  -56.1    1    1    1    0\n",
       "t3     1120362  0.934  295.6   51.7    1    1    0    1\n",
       "t4       64495  0.773  -22.0  -58.9    1    1    0    0\n",
       "t5      125029  0.417   87.7 -555.8    0    1    1    1\n",
       "t6       24099  0.401   16.6 -111.6    1    0    0    1\n",
       "t7       90981  0.288   10.1 -473.9    0    1    0    1\n",
       "t8      116592  0.692  189.0 -223.2    1    0    1    1\n",
       "t9     1345595  0.887  416.3 -197.3    1    0    1    1\n",
       "t10      80520  0.333 -134.1 -105.0    1    1    1    1\n",
       "t11     797374  0.872  284.0 -125.2    1    0    0    1\n",
       "t12      87261  0.706   17.1 -141.0    0    1    1    1\n",
       "t13      56565  0.736   30.2 -168.8    0    1    1    0\n",
       "t14      59431  0.741   24.7  -22.7    1    0    0    0\n",
       "t15      72134  0.739   23.2 -136.4    0    1    0    0\n",
       "t16      16232  0.710   25.2  -57.0    1    0    1    0\n",
       "total  5206742    NaN    NaN    NaN   11   10    9   10"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_epinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "      <th>s_g</th>\n",
       "      <th>s_r</th>\n",
       "      <th>B_g</th>\n",
       "      <th>B_r</th>\n",
       "      <th>S_g</th>\n",
       "      <th>S_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>t1</td>\n",
       "      <td>114678</td>\n",
       "      <td>0.898</td>\n",
       "      <td>55.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2</td>\n",
       "      <td>22582</td>\n",
       "      <td>0.684</td>\n",
       "      <td>-48.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t3</td>\n",
       "      <td>244642</td>\n",
       "      <td>0.908</td>\n",
       "      <td>105.6</td>\n",
       "      <td>72.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t4</td>\n",
       "      <td>21671</td>\n",
       "      <td>0.862</td>\n",
       "      <td>13.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t5</td>\n",
       "      <td>15088</td>\n",
       "      <td>0.696</td>\n",
       "      <td>11.3</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t6</td>\n",
       "      <td>3718</td>\n",
       "      <td>0.530</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>-14.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t7</td>\n",
       "      <td>23621</td>\n",
       "      <td>0.706</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-37.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t8</td>\n",
       "      <td>17884</td>\n",
       "      <td>0.811</td>\n",
       "      <td>30.9</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t9</td>\n",
       "      <td>131026</td>\n",
       "      <td>0.878</td>\n",
       "      <td>68.2</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t10</td>\n",
       "      <td>20185</td>\n",
       "      <td>0.651</td>\n",
       "      <td>-40.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t11</td>\n",
       "      <td>35120</td>\n",
       "      <td>0.883</td>\n",
       "      <td>42.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t12</td>\n",
       "      <td>3851</td>\n",
       "      <td>0.842</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t13</td>\n",
       "      <td>11297</td>\n",
       "      <td>0.843</td>\n",
       "      <td>18.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t14</td>\n",
       "      <td>6675</td>\n",
       "      <td>0.715</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t15</td>\n",
       "      <td>3882</td>\n",
       "      <td>0.849</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t16</td>\n",
       "      <td>618</td>\n",
       "      <td>0.798</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td>676538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count   p(+)    s_g   s_r  B_g  B_r  S_g  S_r\n",
       "t1     114678  0.898   55.6  32.1    1    1    1    1\n",
       "t2      22582  0.684  -48.9  10.5    1    0    1    1\n",
       "t3     244642  0.908  105.6  72.3    1    1    0    1\n",
       "t4      21671  0.862   13.6  16.6    0    0    1    1\n",
       "t5      15088  0.696   11.3 -40.3    0    1    1    1\n",
       "t6       3718  0.530  -16.8 -14.3    0    0    1    1\n",
       "t7      23621  0.706   15.3 -37.3    0    1    0    1\n",
       "t8      17884  0.811   30.9  -3.1    1    0    1    1\n",
       "t9     131026  0.878   68.2  17.2    1    1    1    0\n",
       "t10     20185  0.651  -40.4   1.7    1    0    1    0\n",
       "t11     35120  0.883   42.2  19.3    1    1    0    0\n",
       "t12      3851  0.842    9.1   4.6    0    0    1    0\n",
       "t13     11297  0.843   18.4  -1.0    0    1    1    0\n",
       "t14      6675  0.715   -7.5   9.1    0    1    1    1\n",
       "t15      3882  0.849   12.5   4.1    0    0    0    1\n",
       "t16       618  0.798    2.8   1.8    1    1    1    1\n",
       "total  676538    NaN    NaN   NaN    8    9   12   11"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_links_census_meaned_reddit(graph):\n",
    "    census = {\n",
    "        f't{i}': {\n",
    "            '+': 0,\n",
    "            '-': 0\n",
    "    } for i in range(1, 17)}\n",
    "    \n",
    "    census_edges = {\n",
    "        f't{i}' : [] for i in range(1, 17)\n",
    "    }\n",
    "    \n",
    "    c_links_names = [f't{i}' for i in range(1, 17)]\n",
    "    \n",
    "    census = pd.DataFrame(0, index = pd.Index(c_links_names), columns = ['+', '-']) \n",
    "    \n",
    "    for v in graph:\n",
    "        vnbrs = set(graph.succ[v])\n",
    "        \n",
    "        for u in vnbrs:\n",
    "            neighbors_all = {\n",
    "                ('wv', 'wu'): (set(graph.pred[v]) & set(graph.pred[u])) - {u, v},\n",
    "                ('wv', 'uw'): (set(graph.pred[v]) & set(graph.succ[u])) - {u, v},\n",
    "                ('vw', 'wu'): (vnbrs & set(graph.pred[u])) - {u, v},\n",
    "                ('vw', 'uw'): (vnbrs & set(graph.succ[u])) - {u, v}\n",
    "            }\n",
    "            \n",
    "            for key, neighbors in neighbors_all.items():\n",
    "                for w in neighbors:\n",
    "                    mapping = {\n",
    "                            'wv': (w, v),\n",
    "                            'vw': (v, w),\n",
    "                            'wu': (w, u),\n",
    "                            'uw': (u, w)\n",
    "                        }\n",
    "                    \n",
    "                    edge_1 = mapping[key[0]]\n",
    "                    edge_2 = mapping[key[1]]\n",
    "                    \n",
    "                    if(graph[v][u]['Date'] > graph[edge_1[0]][edge_1[1]]['Date'] and \n",
    "                       graph[v][u]['Date'] > graph[edge_2[0]][edge_2[1]]['Date']):\n",
    "\n",
    "                        c_link_index = []\n",
    "\n",
    "                        sign_edge_1 = graph[edge_1[0]][edge_1[1]]['Sign']\n",
    "                        sign_edge_2 = graph[edge_2[0]][edge_2[1]]['Sign']\n",
    "\n",
    "                    #    c_link_index.append((key[0], sign_edge_1))\n",
    "                    #    c_link_index.append((key[1], sign_edge_2))\n",
    "                        \n",
    "                        if (sign_edge_1 >= 0) : \n",
    "                            c_link_index.append((key[0], 1))\n",
    "                        else: c_link_index.append((key[0],-1))\n",
    "                            \n",
    "                        if (sign_edge_2 >= 0) : \n",
    "                            c_link_index.append((key[1], 1))\n",
    "                        else: c_link_index.append((key[1],-1))    \n",
    "\n",
    "                        c_link_type = C_LINKS_TYPES[tuple(sorted(c_link_index))]\n",
    "\n",
    "                        vu_sign = graph[v][u]['Sign']\n",
    "\n",
    "                        sign_idx = '+' if vu_sign >= 0 else '-'\n",
    "                        \n",
    "#                         not_allowed.add(tuple(sorted([v, u, w])))\n",
    "\n",
    "                        census.loc[c_link_type][sign_idx] += 1\n",
    "                        census_edges[c_link_type].append((v, u))\n",
    "                    \n",
    "    return census, census_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_link_census_reddit_meaned, edges_per_c_link_reddit_meaned = c_links_census_meaned_reddit(graph_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "t1\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t2\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t3\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t4\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t5\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t6\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t7\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t8\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t9\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t10\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t11\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t12\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t13\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t14\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t15\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n",
      "================================================================================\n",
      "t16\n",
      "Beginning generative baseline ...\n",
      "Generative baseline finished !\n",
      "Beginning receptive baseline ...\n",
      "Receptive baseline finished !\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "predictions_reddit = build_predictions(c_link_census_reddit_meaned, edges_per_c_link_reddit_meaned, graph_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>p(+)</th>\n",
       "      <th>s_g</th>\n",
       "      <th>s_r</th>\n",
       "      <th>B_g</th>\n",
       "      <th>B_r</th>\n",
       "      <th>S_g</th>\n",
       "      <th>S_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>t1</td>\n",
       "      <td>1097742</td>\n",
       "      <td>0.954</td>\n",
       "      <td>442.0</td>\n",
       "      <td>330.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t2</td>\n",
       "      <td>65239</td>\n",
       "      <td>0.931</td>\n",
       "      <td>114.5</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t3</td>\n",
       "      <td>985168</td>\n",
       "      <td>0.945</td>\n",
       "      <td>384.2</td>\n",
       "      <td>306.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t4</td>\n",
       "      <td>60321</td>\n",
       "      <td>0.929</td>\n",
       "      <td>107.1</td>\n",
       "      <td>88.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t5</td>\n",
       "      <td>96831</td>\n",
       "      <td>0.903</td>\n",
       "      <td>170.5</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t6</td>\n",
       "      <td>7770</td>\n",
       "      <td>0.882</td>\n",
       "      <td>48.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t7</td>\n",
       "      <td>76253</td>\n",
       "      <td>0.883</td>\n",
       "      <td>136.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t8</td>\n",
       "      <td>7227</td>\n",
       "      <td>0.873</td>\n",
       "      <td>43.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t9</td>\n",
       "      <td>1004639</td>\n",
       "      <td>0.961</td>\n",
       "      <td>355.9</td>\n",
       "      <td>332.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t10</td>\n",
       "      <td>69943</td>\n",
       "      <td>0.940</td>\n",
       "      <td>100.7</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t11</td>\n",
       "      <td>402251</td>\n",
       "      <td>0.959</td>\n",
       "      <td>216.4</td>\n",
       "      <td>207.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t12</td>\n",
       "      <td>23775</td>\n",
       "      <td>0.938</td>\n",
       "      <td>57.3</td>\n",
       "      <td>57.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t13</td>\n",
       "      <td>81585</td>\n",
       "      <td>0.944</td>\n",
       "      <td>111.2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t14</td>\n",
       "      <td>13108</td>\n",
       "      <td>0.937</td>\n",
       "      <td>45.5</td>\n",
       "      <td>37.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t15</td>\n",
       "      <td>25198</td>\n",
       "      <td>0.934</td>\n",
       "      <td>62.1</td>\n",
       "      <td>50.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>t16</td>\n",
       "      <td>2168</td>\n",
       "      <td>0.920</td>\n",
       "      <td>19.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>total</td>\n",
       "      <td>4019218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count   p(+)    s_g    s_r  B_g  B_r  S_g  S_r\n",
       "t1     1097742  0.954  442.0  330.6    1    1    1    1\n",
       "t2       65239  0.931  114.5   80.2    0    0    0    1\n",
       "t3      985168  0.945  384.2  306.4    1    1    0    1\n",
       "t4       60321  0.929  107.1   88.5    0    0    1    1\n",
       "t5       96831  0.903  170.5   64.9    0    0    1    0\n",
       "t6        7770  0.882   48.1   18.7    1    1    0    0\n",
       "t7       76253  0.883  136.4   57.0    0    0    0    0\n",
       "t8        7227  0.873   43.1   23.2    1    1    1    0\n",
       "t9     1004639  0.961  355.9  332.6    1    1    1    0\n",
       "t10      69943  0.940  100.7   86.0    0    0    0    0\n",
       "t11     402251  0.959  216.4  207.6    1    1    0    0\n",
       "t12      23775  0.938   57.3   57.6    0    0    1    0\n",
       "t13      81585  0.944  111.2   90.6    0    0    1    1\n",
       "t14      13108  0.937   45.5   37.4    1    1    0    1\n",
       "t15      25198  0.934   62.1   50.4    0    0    0    1\n",
       "t16       2168  0.920   19.5   16.6    1    1    1    1\n",
       "total  4019218    NaN    NaN    NaN    8    8    8    8"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will try and create clusters/communities from the individuals datasets (Epinions, wikipedi, slashdot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried several algorithms and techniques to produce a meaningful seperation of individuals and tronsform them to communities, but all the methods that we tried from networkx were very computational heavy and we couldn't obtain any result.\n",
    "Note that we also tried to generate clusters (from which we could have treated as communities, but even those algorithms were infeasable). We disregarded the used methods but we can state that we tried \"asyn_lpa_communities\" that detects communities in Graph asynchronous label propagation, the Girvan–Newman method \"girvan_newman(), k_clique_communities .. etc\n",
    "We \n",
    "\n",
    "\n",
    "As a consequence we tried to reproduce an algorithm that we learn about in a paper : Community Detection in Weighted Networks:\n",
    "Algorithms and Applications (link : https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6526730) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigma(G,Community,weight_sum_community):\n",
    "    cut = cut_size(G,Community,set(G.nodes())-Community,'sign')\n",
    "    return cut/weight_sum_community\n",
    "\n",
    "def compute_sum_weights(G,Community,weight_c,selected_node):\n",
    "    summed = weight_c\n",
    "    for node in Community:\n",
    "        if G.has_edge(selected_node,node):\n",
    "            summed+=G[selected_node][node]['sign']\n",
    "        if G.has_edge(node,selected_node):\n",
    "            summed+=G[node][selected_node]['sign']\n",
    "    return summed\n",
    "\n",
    "def detection_algorithm(G):\n",
    "    E = set(G.edges())\n",
    "    C_set = set()\n",
    "    \n",
    "    pos_edges = [e for e in E if G[e[0]][e[1]]['sign'] == 1]\n",
    "    neg_edges = [e for e in E if G[e[0]][e[1]]['sign'] == -1]\n",
    "    weight_c = 0\n",
    "    while len(E)!= 0:\n",
    "        print(80*'=')\n",
    "        print('len(E)=',len(E))\n",
    "        print(80*'=')\n",
    "        if (len(pos_edges)!=0) : e=pos_edges.pop(-1)\n",
    "        else: e=neg_edges.pop(-1)\n",
    "        C = set()\n",
    "        C.add(e[0])\n",
    "        C.add(e[1])\n",
    "        weight_c+=G[e[0]][e[1]]['sign']\n",
    "        Nc=set()\n",
    "        for v in C:\n",
    "            Nc=Nc | set(G.neighbors(v))\n",
    "        print(len(Nc))\n",
    "        while len(Nc)!=0:\n",
    "            if len(Nc)%10 == 0 : print('len(Nc) =',len(Nc))\n",
    "            nodes=[]\n",
    "            values=[]\n",
    "            for n in C:\n",
    "                k_node=0\n",
    "                neighbors = [node for node in G if G.has_edge(node,n) and node not in C]\n",
    "                for elem in neighbors:\n",
    "                    if G.has_edge(elem,n):\n",
    "                        k_node+=G[elem][n]['sign']\n",
    "                    else: #G.has_edge(n,elem): \n",
    "                        k_node+=G[n][elem]['sign']\n",
    "                    nodes.append(elem)\n",
    "                    values.append(compute_BwC(G,elem,C,k_node))\n",
    "            selected_node = nodes[np.argmax(values)]\n",
    "            Nc=Nc- {selected_node}\n",
    "            C1 = C | {selected_node}\n",
    "            sigma_C1 = compute_sigma(G,C1,compute_sum_weights(G,C1,weight_c,selected_node))\n",
    "            sigma_C = compute_sigma(G,C,weight_c)\n",
    "            if sigma_C1<sigma_C :\n",
    "                C=C1\n",
    "            else: \n",
    "                break\n",
    "        E = E - set(G.subgraph(C).edges())\n",
    "        C_set = C_set | C\n",
    "    return C_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even this algorithm was very heavy to compute ie: O(|V|²) and thus we failed to accomplish the part of comparing communities of individuals from Epinions , to communities in Reddit (subreddits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This motivated us to work more on the presentations and since our data have informations about the timestamp of each created edge, we decided to work on interactive visualisations of graphs and nodes in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show\n",
    "from bokeh.models import (BoxZoomTool, Circle, HoverTool,\n",
    "                          MultiLine, Plot, Range1d, ResetTool, Arc, Button, CustomJS,\n",
    "                          TapTool, BoxSelectTool, EdgesAndLinkedNodes, NodesAndLinkedEdges)\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "## Helper functions that sorts the nodes and creates a a grid layout\n",
    "def grid_layout_with_ordering(G, nb_rows=4, ordering='GENERATIVE'):\n",
    "    counts_df = pd.DataFrame(0, index = pd.Index([id_ for id_ in G.nodes()]), columns=['IN+', 'IN-', 'OUT+', 'OUT-'])\n",
    "    \n",
    "    result_dict = {\n",
    "        id_ : None for id_ in G.nodes()\n",
    "    }\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        sign = G[edge[0]][edge[1]]['Sign']\n",
    "        \n",
    "        sign_str = '+' if sign == 1 else '-'\n",
    "        \n",
    "        counts_df.loc[edge[0], 'OUT'+sign_str] += 1\n",
    "        counts_df.loc[edge[1], 'IN'+sign_str] += 1\n",
    "\n",
    "        \n",
    "    counts_df['GENERATIVE_SCORE'] = (counts_df['OUT+'] - counts_df['OUT-']) / (counts_df['OUT+'] + counts_df['OUT-'])\n",
    "    counts_df['RECEPTIVE_SCORE'] = (counts_df['IN+'] - counts_df['IN-']) / (counts_df['IN+'] + counts_df['IN-'])\n",
    "    \n",
    "    counts_df = counts_df.replace([np.inf, -np.inf], np.nan)\n",
    "    counts_df = counts_df.replace([np.nan], 0)\n",
    "    \n",
    "    if(ordering == 'GENERATIVE'):\n",
    "        counts_df.sort_values(by='GENERATIVE_SCORE', axis=0, ascending=False, inplace=True)\n",
    "    else:\n",
    "        counts_df.sort_values(by='RECEPTIVE_SCORE', axis=0, ascending=False, inplace=True)\n",
    "\n",
    "    nb_nodes = counts_df.shape[0]\n",
    "    \n",
    "    nb_cols = math.ceil(nb_nodes/nb_rows)\n",
    "    \n",
    "    xs = np.linspace(-1, 1, nb_cols)\n",
    "    X = xs.shape[0]\n",
    "    \n",
    "    ys = np.linspace(1, -1, nb_rows)\n",
    "    Y = ys.shape[0]\n",
    "    \n",
    "    completed = False\n",
    "          \n",
    "    for idx_y, y in enumerate(ys):\n",
    "\n",
    "        \n",
    "        for idx_x, x in enumerate(xs):\n",
    "            idx_all = idx_y * X + idx_x\n",
    "            \n",
    "            if(idx_all >= nb_nodes):\n",
    "                completed = False\n",
    "                break\n",
    "            \n",
    "            node = counts_df.index[idx_all]\n",
    "            pos = np.array([x, y])\n",
    "            \n",
    "            result_dict[node] = pos\n",
    "            \n",
    "        if(completed):\n",
    "            break\n",
    "        \n",
    "    return result_dict, counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>Sign</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>100daysofketo</td>\n",
       "      <td>keto</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/05/07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>30daystosortmylifeout</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/12/01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>100daysofrejection</td>\n",
       "      <td>howtonotgiveafuck</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/11/14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieaweek</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>100movies365days</td>\n",
       "      <td>movieclub</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014/07/12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339586</td>\n",
       "      <td>zorceror44</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/08/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339596</td>\n",
       "      <td>zreviews</td>\n",
       "      <td>audiophile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/06/25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339634</td>\n",
       "      <td>zylooxwrites</td>\n",
       "      <td>writingprompts</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015/11/05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339635</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/11/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>339637</td>\n",
       "      <td>zyramains</td>\n",
       "      <td>summonerschool</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016/06/17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36966 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                 target  Sign        Date\n",
       "22           100daysofketo                   keto   1.0  2016/05/07\n",
       "25      100daysofrejection  30daystosortmylifeout   1.0  2015/12/01\n",
       "27      100daysofrejection      howtonotgiveafuck   1.0  2015/11/14\n",
       "30        100movies365days             movieaweek   1.0  2014/07/12\n",
       "31        100movies365days              movieclub   1.0  2014/07/12\n",
       "...                    ...                    ...   ...         ...\n",
       "339586          zorceror44         writingprompts   1.0  2016/08/25\n",
       "339596            zreviews             audiophile   1.0  2016/06/25\n",
       "339634        zylooxwrites         writingprompts   1.0  2015/11/05\n",
       "339635           zyramains        leagueoflegends   1.0  2016/11/16\n",
       "339637           zyramains         summonerschool   1.0  2016/06/17\n",
       "\n",
       "[36966 rows x 4 columns]"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_edges_meaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "meaned_graph_more3links = nx.from_pandas_edgelist(multiple_edges_meaned_data,source='source', target=\"target\", edge_attr = [\"Sign\",\"Date\"],create_using=nx.DiGraph)\n",
    "reddit_grid_pos, reddit_scores_df = grid_layout_with_ordering(meaned_graph_more3links, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create graph for visaulisation : (we discard the nodes implicated in less than 3 links)\n",
    "meaned_graph_more3links = nx.from_pandas_edgelist(multiple_edges_meaned_data,source='source', target=\"target\", edge_attr = [\"Sign\",\"Date\"],create_using=nx.DiGraph)\n",
    "\n",
    "wikipedia_grid_pos, wikipedia_scores_df = grid_layout_with_ordering(wikipedia_graph, 40)\n",
    "reddit_grid_pos, reddit_scores_df = grid_layout_with_ordering(meaned_graph_more3links, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dict { date : [nodes_active] } and dict { date : [edges_active]} for later use\n",
    "## was done in javascript instead\n",
    "\n",
    "def nodes_and_edges_per_date(G, dates, graph_renderer):\n",
    "    froms = np.array(graph_renderer.edge_renderer.data_source.data['start'])\n",
    "    tos = np.array(graph_renderer.edge_renderer.data_source.data['end'])\n",
    "    Date = np.array(graph_renderer.edge_renderer.data_source.data['Date'])    \n",
    "    nodes = np.array(graph_renderer.node_renderer.data_source.data['index'])\n",
    "    \n",
    "    edges_dict = {\n",
    "        date : [] for date in dates\n",
    "    }\n",
    "\n",
    "    nodes_dict = {\n",
    "        date : [] for date in dates\n",
    "    }\n",
    "    \n",
    "    for date in dates:\n",
    "        indices = np.where(Date == date)\n",
    "        \n",
    "        edges = indices\n",
    "\n",
    "        edges_dict[date] = list(edges)\n",
    "\n",
    "        nodes = set(froms[indices]) | set(tos[indices])\n",
    "\n",
    "        nodes_dict[date] = list(nodes)\n",
    "        \n",
    "    return nodes_dict, edges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JS code for bokehJS\n",
    "\n",
    "START_CODE = \"\"\" \n",
    "        if(dataset_title === 'wikipedia') {\n",
    "        \n",
    "        \n",
    "        nb_clicks_wikipedia = nb_clicks_wikipedia + 1\n",
    "        \n",
    "        if(nb_clicks_wikipedia != 1) {\n",
    "            nb_clicks_wikipedia = nb_clicks_wikipedia - 1\n",
    "            return\n",
    "        }\n",
    "        \n",
    "        simulation_in_progress_wikipedia = true\n",
    "\n",
    "        var active_edges_idx = []\n",
    "        var active_edges = {}\n",
    "        var active_nodes = []\n",
    "        \n",
    "        var all_nodes = graph_renderer.node_renderer.data_source.data['index']\n",
    "        \n",
    "        if(isEmpty(nodes_dict_wikipedia) || isEmpty(edges_dict_wikipedia)) {\n",
    "            dates_arr_wikipedia.forEach(function (date, index) {\n",
    "                edges_dict_wikipedia[date] = backup_copy['Date'].reduce(function(a, e, i) {\n",
    "                    if (e === date)\n",
    "                        a.push(i);\n",
    "                    return a;\n",
    "                }, []); \n",
    "\n",
    "                nodes_dict_wikipedia[date] = backup_copy['Date'].reduce(function(a, e, i) {\n",
    "                    if (e === date) {\n",
    "                        a.add(all_nodes.indexOf(backup_copy['start'][i]));\n",
    "                        a.add(all_nodes.indexOf(backup_copy['end'][i]))\n",
    "                    }   \n",
    "                    return a;\n",
    "                }, new Set([])); \n",
    "\n",
    "            });\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "        var all_edges = {\n",
    "            'Sign': [],\n",
    "            'Date': [],\n",
    "            'edge_color_selection': [],\n",
    "            'start': [],\n",
    "            'end': []\n",
    "        }\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.data = all_edges\n",
    "        \n",
    "        function loop() {\n",
    "            if(simulation_in_progress_wikipedia == false || date_idx_wikipedia == dates_arr_wikipedia.length)\n",
    "            {\n",
    "                nb_clicks_wikipedia = 0\n",
    "                return\n",
    "            }\n",
    "            \n",
    "            var date = dates_arr_wikipedia[date_idx_wikipedia]\n",
    "            \n",
    "            active_edges_idx = edges_dict_wikipedia[date]\n",
    "            active_nodes = nodes_dict_wikipedia[date]\n",
    "            \n",
    "            active_edges = {\n",
    "                'Sign': [],\n",
    "                'Date': [],\n",
    "                'edge_color_selection': [],\n",
    "                'start': [],\n",
    "                'end': []\n",
    "            }\n",
    "            \n",
    "            var old_count = all_edges['Sign'].length\n",
    "            \n",
    "            active_edges_idx.forEach(function (edge_idx, index) {\n",
    "                active_edges['Sign'].push(backup_copy['Sign'][edge_idx])\n",
    "                active_edges['Date'].push(backup_copy['Date'][edge_idx])\n",
    "                active_edges['edge_color_selection'].push(backup_copy['edge_color_selection'][edge_idx])\n",
    "                active_edges['start'].push(backup_copy['start'][edge_idx])\n",
    "                active_edges['end'].push(backup_copy['end'][edge_idx])\n",
    "            });\n",
    "        \n",
    "            all_edges = {\n",
    "                'Sign': all_edges['Sign'].concat(active_edges['Sign']) ,\n",
    "                'Date': all_edges['Date'].concat(active_edges['Date']),\n",
    "                'edge_color_selection': all_edges['edge_color_selection'].concat(active_edges['edge_color_selection']),\n",
    "                'start': all_edges['start'].concat(active_edges['start']),\n",
    "                'end': all_edges['end'].concat(active_edges['end'])\n",
    "            }\n",
    "            \n",
    "            graph_renderer.edge_renderer.data_source.data = all_edges\n",
    "            \n",
    "            var indices = [...Array(all_edges['Sign'].length).keys()].map(i => i + old_count) ;\n",
    "\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = indices\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = Array.from(active_nodes)\n",
    "\n",
    "\n",
    "            date_idx_wikipedia = date_idx_wikipedia + 1\n",
    "             \n",
    "            setTimeout(loop, 700)\n",
    "        \n",
    "        }\n",
    "        \n",
    "        loop()\n",
    "        \n",
    "        nb_clicks_wikipedia = 0\n",
    "        date_idx_wikipedia = 0\n",
    "        \n",
    "        \n",
    "        } else {\n",
    "        \n",
    "        \n",
    "        nb_clicks_reddit = nb_clicks_reddit + 1\n",
    "        \n",
    "        if(nb_clicks_reddit != 1) {\n",
    "            nb_clicks_reddit = nb_clicks_reddit - 1\n",
    "            return\n",
    "        }\n",
    "        \n",
    "        simulation_in_progress_reddit = true\n",
    "\n",
    "        var active_edges_idx = []\n",
    "        var active_edges = {}\n",
    "        var active_nodes = []\n",
    "        \n",
    "        var all_nodes = graph_renderer.node_renderer.data_source.data['index']\n",
    "        \n",
    "        if(isEmpty(nodes_dict_reddit) || isEmpty(edges_dict_reddit)) {\n",
    "            dates_arr_reddit.forEach(function (date, index) {\n",
    "                edges_dict_reddit[date] = backup_copy['Date'].reduce(function(a, e, i) {\n",
    "                    if (e === date)\n",
    "                        a.push(i);\n",
    "                    return a;\n",
    "                }, []); \n",
    "\n",
    "                nodes_dict_reddit[date] = backup_copy['Date'].reduce(function(a, e, i) {\n",
    "                    if (e === date) {\n",
    "                        a.add(all_nodes.indexOf(backup_copy['start'][i]));\n",
    "                        a.add(all_nodes.indexOf(backup_copy['end'][i]))\n",
    "                    }   \n",
    "                    return a;\n",
    "                }, new Set([])); \n",
    "\n",
    "            });\n",
    "        }\n",
    "        \n",
    "\n",
    "        \n",
    "        var all_edges = {\n",
    "            'Sign': [],\n",
    "            'Date': [],\n",
    "            'edge_color_selection': [],\n",
    "            'start': [],\n",
    "            'end': []\n",
    "        }\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.data = all_edges\n",
    "        \n",
    "        function loop() {\n",
    "            if(simulation_in_progress_reddit == false || date_idx_reddit == dates_arr_reddit.length)\n",
    "            {\n",
    "                nb_clicks_reddit = 0\n",
    "                return\n",
    "            }\n",
    "            \n",
    "            var date = dates_arr_reddit[date_idx_reddit]\n",
    "            \n",
    "            active_edges_idx = edges_dict_reddit[date]\n",
    "            active_nodes = nodes_dict_reddit[date]\n",
    "            \n",
    "            active_edges = {\n",
    "                'Sign': [],\n",
    "                'Date': [],\n",
    "                'edge_color_selection': [],\n",
    "                'start': [],\n",
    "                'end': []\n",
    "            }\n",
    "            \n",
    "            var old_count = all_edges['Sign'].length\n",
    "            \n",
    "            active_edges_idx.forEach(function (edge_idx, index) {\n",
    "                active_edges['Sign'].push(backup_copy['Sign'][edge_idx])\n",
    "                active_edges['Date'].push(backup_copy['Date'][edge_idx])\n",
    "                active_edges['edge_color_selection'].push(backup_copy['edge_color_selection'][edge_idx])\n",
    "                active_edges['start'].push(backup_copy['start'][edge_idx])\n",
    "                active_edges['end'].push(backup_copy['end'][edge_idx])\n",
    "            });\n",
    "        \n",
    "            all_edges = {\n",
    "                'Sign': all_edges['Sign'].concat(active_edges['Sign']) ,\n",
    "                'Date': all_edges['Date'].concat(active_edges['Date']),\n",
    "                'edge_color_selection': all_edges['edge_color_selection'].concat(active_edges['edge_color_selection']),\n",
    "                'start': all_edges['start'].concat(active_edges['start']),\n",
    "                'end': all_edges['end'].concat(active_edges['end'])\n",
    "            }\n",
    "            \n",
    "            graph_renderer.edge_renderer.data_source.data = all_edges\n",
    "            \n",
    "            var indices = [...Array(all_edges['Sign'].length).keys()].map(i => i + old_count) ;\n",
    "\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = indices\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = Array.from(active_nodes)\n",
    "\n",
    "\n",
    "            date_idx_reddit = date_idx_reddit + 1\n",
    "             \n",
    "            setTimeout(loop, 700)\n",
    "        \n",
    "        }\n",
    "        \n",
    "        loop()\n",
    "        \n",
    "        nb_clicks_reddit = 0\n",
    "        date_idx_reddit = 0\n",
    "        \n",
    "        \n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "PAUSE_CODE = \"\"\" \n",
    "                if(dataset_title === 'wikipedia') {\n",
    "        simulation_in_progress_wikipedia = false\n",
    "        } else {\n",
    "        simulation_in_progress_reddit = false\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "END_CODE = \"\"\" \n",
    "        if(dataset_title === 'wikipedia') {\n",
    "            simulation_in_progress_wikipedia = false\n",
    "            date_idx_wikipedia = 0\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = []\n",
    "        } else {\n",
    "            simulation_in_progress_reddit = false\n",
    "            date_idx_reddit = 0\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = []\n",
    "        \n",
    "        \n",
    "        }\n",
    "\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import column, row\n",
    "from bokeh.embed import components, json_item\n",
    "import copy\n",
    "import json\n",
    "\n",
    "## Make everything and create the component for the visualization. (time simulation)\n",
    "## dump it to json, and use it later in the html/js as a json got async\n",
    "def create_viz_timing(G, pos_dict, dates, dataset_title, plot_width=1850, plot_height=1080):\n",
    "    POSITIVE_COLOR_SELECTION, NEGATIVE_COLOR_SELECTION = \"#27FF00\", \"#FF2A00\"\n",
    "    \n",
    "    edge_attrs_selection = {}\n",
    "    \n",
    "    for start_node, end_node, _ in G.edges(data=True):\n",
    "        edge_color_selection = POSITIVE_COLOR_SELECTION if G[start_node][end_node]['Sign'] > 0 else NEGATIVE_COLOR_SELECTION\n",
    "\n",
    "        edge_attrs_selection[(start_node, end_node)] = edge_color_selection\n",
    "        \n",
    "    nx.set_edge_attributes(G, edge_attrs_selection, \"edge_color_selection\")\n",
    "    \n",
    "    plot = Plot(plot_width=plot_width, plot_height=plot_height,\n",
    "            x_range=Range1d(-1.1, 1.1), y_range=Range1d(-1.1, 1.1))\n",
    "    \n",
    "    graph_renderer = from_networkx(G, pos_dict)\n",
    "    \n",
    "#     nodes_dict, edges_dict = nodes_and_edges_per_date(G, dates, graph_renderer)\n",
    "    \n",
    "    graph_renderer.node_renderer.glyph = Circle(size=5, fill_color=\"blue\")\n",
    "    graph_renderer.node_renderer.selection_glyph = Circle(size=5, fill_color=\"red\")\n",
    "\n",
    "    graph_renderer.edge_renderer.glyph = MultiLine(line_color=\"#CCCCCC\", line_alpha=0.8, line_width=1)\n",
    "    graph_renderer.edge_renderer.selection_glyph = MultiLine(line_color=\"edge_color_selection\", line_width=2.5)\n",
    "    \n",
    "    plot.renderers.append(graph_renderer)\n",
    "    \n",
    "    button_start = Button(label='Start', button_type=\"success\")\n",
    "    button_pause = Button(label='Pause', button_type=\"warning\")\n",
    "    button_end = Button(label='End', button_type=\"danger\")\n",
    "    \n",
    "    backup_edges_data = copy.deepcopy(graph_renderer.edge_renderer.data_source.data)\n",
    "    \n",
    "    start_callback = CustomJS(args= dict(\n",
    "        dataset_title = dataset_title,\n",
    "        graph_renderer = graph_renderer,\n",
    "        backup_copy = backup_edges_data\n",
    "    ), code = START_CODE)\n",
    "\n",
    "    button_start.js_on_click(start_callback)\n",
    "    \n",
    "    pause_callback = CustomJS(args= dict(\n",
    "        dataset_title = dataset_title\n",
    "    ), code = PAUSE_CODE)\n",
    "    \n",
    "    button_pause.js_on_click(pause_callback)\n",
    "    \n",
    "    end_callback = CustomJS(args= dict(\n",
    "        dataset_title = dataset_title,\n",
    "        graph_renderer = graph_renderer\n",
    "    ),code = END_CODE)\n",
    "\n",
    "    button_end.js_on_click(end_callback)\n",
    "    \n",
    "#     output_file(\"interactive_graphs.html\")\n",
    "\n",
    "    button_start.css_classes.append('my-button')\n",
    "    button_pause.css_classes.append('my-button')\n",
    "    button_end.css_classes.append('my-button')\n",
    "\n",
    "    layout_row = row(button_start, button_pause, button_end)\n",
    "\n",
    "    layout_row.css_classes.append('button-row')\n",
    "\n",
    "    layout_column = column(layout_row, plot)\n",
    "\n",
    "    layout_column.css_classes.append('bk-container')\n",
    "\n",
    "#     show(column(layout_column))  \n",
    "    \n",
    "    json_ = json_item(layout_column, \"wikipedia-plot\")\n",
    "    \n",
    "    with open('embedabble_'+ dataset_title + '_demo.json', 'w') as outfile:\n",
    "        json.dump(json_, outfile)\n",
    "        \n",
    "    with open(dataset_title + '_dates.json', 'w') as outfile:\n",
    "        json.dump(dates, outfile)\n",
    "    \n",
    "def extract_dates(df):\n",
    "    dates = set(df['Date'].values.tolist())\n",
    "    dates = sorted(list(dates))\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "## JS code for bokehJS\n",
    "\n",
    "OUT_CODE = \"\"\" \n",
    "\n",
    "console.log(graph_renderer)\n",
    "        if(dataset_title === 'wikipedia') {\n",
    "        \n",
    "        $(this)\n",
    "                                        var buttons = $('.wikipedia-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('outgoing'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "        \n",
    "        \n",
    "        ingoing_wikipedia = false\n",
    "        outgoing_wikipedia = true\n",
    "                \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_outgoing_wikipedia\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_outgoing_wikipedia.concat(selected_prime_node_wikipedia)\n",
    "        \n",
    "        } else {\n",
    "        \n",
    "                                                var buttons = $('.reddit-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('outgoing'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "        \n",
    "        ingoing_reddit = false\n",
    "        outgoing_reddit = true\n",
    "                \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_outgoing_reddit\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_outgoing_reddit.concat(selected_prime_node_reddit)\n",
    "        \n",
    "        }\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "IN_CODE = \"\"\" \n",
    "\n",
    "        console.log(graph_renderer)\n",
    "        \n",
    "        if(dataset_title === 'wikipedia') {\n",
    "        \n",
    "                                        var buttons = $('.wikipedia-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('ingoing'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "        \n",
    "        ingoing_wikipedia = true\n",
    "        outgoing_wikipedia = false\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_ingoing_wikipedia\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_ingoing_wikipedia.concat(selected_prime_node_wikipedia)\n",
    "        \n",
    "        \n",
    "        \n",
    "        } else {\n",
    "        \n",
    "            var buttons = $('.reddit-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('ingoing'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "        \n",
    "        ingoing_reddit = true\n",
    "        outgoing_reddit = false\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_ingoing_reddit\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_ingoing_reddit.concat(selected_prime_node_reddit)\n",
    "        \n",
    "        \n",
    "        \n",
    "        }\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "BOTH_CODE = \"\"\" \n",
    "\n",
    "        console.log(graph_renderer)\n",
    "        \n",
    "\n",
    "        \n",
    "        if(dataset_title === 'wikipedia') {\n",
    "                \n",
    "        var buttons = $('.wikipedia-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('both'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "                \n",
    "                \n",
    "                ingoing_wikipedia = true\n",
    "        outgoing_wikipedia = true\n",
    "        \n",
    "                var all_edges = selected_edges_ingoing_wikipedia.concat(selected_edges_outgoing_wikipedia)\n",
    "        all_edges.sort()\n",
    "        var all_nodes = selected_non_prime_ingoing_wikipedia.concat(selected_non_prime_outgoing_wikipedia, selected_prime_node_wikipedia)\n",
    "        all_nodes.sort()\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = all_edges\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = all_nodes\n",
    "        \n",
    "        } else {\n",
    "        \n",
    "                var buttons = $('.reddit-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if($(this).hasClass('both'))\n",
    "                $(this).addClass('active')\n",
    "            else\n",
    "                $(this).removeClass('active')\n",
    "        })\n",
    "        \n",
    "                var all_edges = selected_edges_ingoing_reddit.concat(selected_edges_outgoing_reddit)\n",
    "        all_edges.sort()\n",
    "        var all_nodes = selected_non_prime_ingoing_reddit.concat(selected_non_prime_outgoing_reddit, selected_prime_node_reddit)\n",
    "        all_nodes.sort()\n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = all_edges\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = all_nodes\n",
    "        \n",
    "        \n",
    "        }\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "NONE_CODE = \"\"\" \n",
    "        if(dataset_title === 'wikipedia') {\n",
    "        \n",
    "            var buttons = $('.wikipedia-plot .my-button')\n",
    "\n",
    "            buttons.each(function (index) {\n",
    "                if($(this).hasClass('none'))\n",
    "                    $(this).addClass('active')\n",
    "                else\n",
    "                    $(this).removeClass('active')\n",
    "            })\n",
    "                \n",
    "                ingoing_wikipedia = false\n",
    "        outgoing_wikipedia = false\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_prime_node_wikipedia\n",
    "        \n",
    "        } else {\n",
    "                        var buttons = $('.reddit-plot .my-button')\n",
    "\n",
    "        buttons.each(function (index, item) {\n",
    "            if(item.hasClass('none'))\n",
    "                item.addClass('active')\n",
    "            else\n",
    "                item.removeClass('active')\n",
    "        })\n",
    "        \n",
    "                ingoing_reddit = false\n",
    "        outgoing_reddit = false\n",
    "        \n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_prime_node_reddit\n",
    "        \n",
    "        }\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "CLICKED_CODE = \"\"\" \n",
    "    console.log('first')\n",
    "    console.log(graph_renderer)\n",
    "    console.log(ingoing_wikipedia)\n",
    "    console.log(outgoing_wikipedia)\n",
    "    \n",
    "    console.log('second')\n",
    "    \n",
    "    var selected_nodes = graph_renderer.node_renderer.data_source.selected.indices\n",
    "    \n",
    "    if(selected_nodes === undefined || selected_nodes.length === 0)\n",
    "        return\n",
    "    \n",
    "    if(dataset_title === 'wikipedia') {\n",
    "        var clicked_node_idx = graph_renderer.node_renderer.data_source.selected.indices[0]\n",
    "        var clicked_node = graph_renderer.node_renderer.data_source.data['index'][clicked_node_idx]\n",
    "    \n",
    "        console.log(clicked_node)\n",
    "    \n",
    "        selected_prime_node_wikipedia = [clicked_node_idx]\n",
    "    \n",
    "    \n",
    "        var tab_out = findOutgoingEdgesAndNodes(clicked_node, graph_renderer)\n",
    "        var tab_in = findIngoingEdgesAndNodes(clicked_node, graph_renderer)\n",
    "\n",
    "        selected_edges_outgoing_wikipedia = tab_out[0]\n",
    "        selected_non_prime_outgoing_wikipedia = Array.from(tab_out[1])\n",
    "        selected_edges_ingoing_wikipedia = tab_in[0]\n",
    "        selected_non_prime_ingoing_wikipedia = Array.from(tab_in[1])\n",
    "\n",
    "        console.log(selected_edges_outgoing_wikipedia, selected_non_prime_outgoing_wikipedia)\n",
    "        console.log(selected_edges_ingoing_wikipedia, selected_non_prime_ingoing_wikipedia)\n",
    "\n",
    "        if(ingoing_wikipedia && !outgoing_wikipedia) {\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_ingoing_wikipedia\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_ingoing_wikipedia.concat(selected_prime_node_wikipedia)\n",
    "        }\n",
    "        else if(!ingoing_wikipedia && outgoing_wikipedia) {\n",
    "            console.log('tay1')\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_outgoing_wikipedia\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_outgoing_wikipedia.concat(selected_prime_node_wikipedia)\n",
    "        } else if(ingoing_wikipedia && outgoing_wikipedia){\n",
    "            console.log('tay2')\n",
    "            var all_edges = selected_edges_ingoing_wikipedia.concat(selected_edges_outgoing_wikipedia)\n",
    "            all_edges.sort()\n",
    "            var all_nodes = selected_non_prime_ingoing_wikipedia.concat(selected_non_prime_outgoing_wikipedia, selected_prime_node_wikipedia)\n",
    "            all_nodes.sort()\n",
    "\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = all_edges\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = all_nodes\n",
    "        } else {\n",
    "            console.log('tay3')\n",
    "            graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "            graph_renderer.node_renderer.data_source.selected.indices = selected_prime_node_wikipedia\n",
    "        }\n",
    "        \n",
    "        } else {\n",
    "            var clicked_node_idx = graph_renderer.node_renderer.data_source.selected.indices[0]\n",
    "    var clicked_node = graph_renderer.node_renderer.data_source.data['index'][clicked_node_idx]\n",
    "    \n",
    "    selected_prime_node_reddit = [clicked_node_idx]\n",
    "    \n",
    "        var tab_out = findOutgoingEdgesAndNodes(clicked_node, graph_renderer)\n",
    "    var tab_in = findIngoingEdgesAndNodes(clicked_node, graph_renderer)\n",
    "\n",
    "    selected_edges_outgoing_reddit = tab_out[0]\n",
    "    selected_non_prime_outgoing_reddit = Array.from(tab_out[1])\n",
    "    selected_edges_ingoing_reddit = tab_in[0]\n",
    "    selected_non_prime_ingoing_reddit = Array.from(tab_in[1])\n",
    "\n",
    "    if(ingoing_reddit && !outgoing_reddit) {\n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_ingoing_reddit\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_ingoing_reddit.concat(selected_prime_node_reddit)\n",
    "    }\n",
    "    else if(!ingoing_reddit && outgoing_reddit) {\n",
    "graph_renderer.edge_renderer.data_source.selected.indices = selected_edges_outgoing_reddit\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_non_prime_outgoing_reddit.concat(selected_prime_node_reddit)\n",
    "    \n",
    "    } else if(ingoing_reddit && outgoing_reddit){\n",
    "        var all_edges = selected_edges_ingoing_reddit.concat(selected_edges_outgoing_reddit)\n",
    "        all_edges.sort()\n",
    "        var all_nodes = selected_non_prime_ingoing_reddit.concat(selected_non_prime_outgoing_reddit, selected_prime_node_reddit)\n",
    "        all_nodes.sort()\n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = all_edges\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = all_nodes\n",
    "    } else {\n",
    "        graph_renderer.edge_renderer.data_source.selected.indices = []\n",
    "        graph_renderer.node_renderer.data_source.selected.indices = selected_prime_node_reddit\n",
    "    }\n",
    "        \n",
    "        \n",
    "        }\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import column, row\n",
    "from bokeh.embed import components, json_item\n",
    "import copy\n",
    "from bokeh.events import Tap\n",
    "import json\n",
    "from bokeh.models import WheelZoomTool\n",
    "\n",
    "## Make everything and create the component for the visualization. (picker simulation)\n",
    "\n",
    "def create_viz_picker(G, pos_dict, dataset_title, plot_width=1850, plot_height=1080):\n",
    "    POSITIVE_COLOR_SELECTION, NEGATIVE_COLOR_SELECTION = \"#27FF00\", \"#FF2A00\"\n",
    "    \n",
    "    edge_attrs_selection = {}\n",
    "    \n",
    "    for start_node, end_node, _ in G.edges(data=True):\n",
    "        edge_color_selection = POSITIVE_COLOR_SELECTION if G[start_node][end_node]['Sign'] > 0 else NEGATIVE_COLOR_SELECTION\n",
    "\n",
    "        edge_attrs_selection[(start_node, end_node)] = edge_color_selection\n",
    "        \n",
    "    nx.set_edge_attributes(G, edge_attrs_selection, \"edge_color_selection\")\n",
    "    \n",
    "    plot = Plot(plot_width=plot_width, plot_height=plot_height,\n",
    "            x_range=Range1d(-1.1, 1.1), y_range=Range1d(-1.1, 1.1))\n",
    "    \n",
    "    plot.add_tools(TapTool(), WheelZoomTool())\n",
    "    \n",
    "    graph_renderer = from_networkx(G, pos_dict)\n",
    "    \n",
    "    graph_renderer.node_renderer.glyph = Circle(size=5, fill_color=\"blue\")\n",
    "    graph_renderer.node_renderer.selection_glyph = Circle(size=5, fill_color=\"red\")\n",
    "\n",
    "\n",
    "    graph_renderer.edge_renderer.glyph = MultiLine(line_color=\"#CCCCCC\", line_alpha=0.8, line_width=1)\n",
    "    graph_renderer.edge_renderer.selection_glyph = MultiLine(line_color=\"edge_color_selection\", line_width=2.5)\n",
    "    \n",
    "    plot.renderers.append(graph_renderer)\n",
    "    \n",
    "    button_both = Button(label='Both', button_type=\"success\")\n",
    "    button_ingoing = Button(label='Ingoing edges only', button_type=\"warning\")\n",
    "    button_outgoing = Button(label='Outgoing edges only', button_type=\"warning\")\n",
    "    button_none = Button(label='None', button_type=\"danger\")\n",
    "    \n",
    "    both_callback = CustomJS(args= dict(\n",
    "        graph_renderer = graph_renderer,\n",
    "        dataset_title = dataset_title\n",
    "    ), code = BOTH_CODE)\n",
    "\n",
    "    button_both.js_on_click(both_callback)\n",
    "    \n",
    "    out_callback = CustomJS(args= dict(\n",
    "        graph_renderer = graph_renderer,\n",
    "        dataset_title = dataset_title\n",
    "    ), code = OUT_CODE)\n",
    "\n",
    "    button_outgoing.js_on_click(out_callback)\n",
    "    \n",
    "    in_callback = CustomJS(args= dict(\n",
    "        graph_renderer = graph_renderer,\n",
    "        dataset_title = dataset_title\n",
    "    ), code = IN_CODE)\n",
    "\n",
    "    button_ingoing.js_on_click(in_callback)\n",
    "    \n",
    "    none_callback = CustomJS(args= dict(\n",
    "        graph_renderer = graph_renderer,\n",
    "        dataset_title = dataset_title\n",
    "    ), code = NONE_CODE)\n",
    "\n",
    "    button_none.js_on_click(none_callback)\n",
    "    \n",
    "    click_callback = CustomJS(args=dict(\n",
    "        graph_renderer = graph_renderer,\n",
    "        dataset_title = dataset_title\n",
    "    ), code = CLICKED_CODE)\n",
    "    \n",
    "    plot.js_on_event(Tap, click_callback)\n",
    "\n",
    "    button_both.css_classes.append('my-button')\n",
    "    button_both.css_classes.append('both')\n",
    "    button_outgoing.css_classes.append('my-button')\n",
    "    button_outgoing.css_classes.append('outgoing')\n",
    "    button_ingoing.css_classes.append('my-button')\n",
    "    button_ingoing.css_classes.append('ingoing')\n",
    "    button_none.css_classes.append('my-button')\n",
    "    button_none.css_classes.append('none')\n",
    "\n",
    "    layout_row = row(button_both, button_outgoing, button_ingoing, button_none)\n",
    "\n",
    "    layout_row.css_classes.append('button-row')\n",
    "\n",
    "    layout_column = column(layout_row, plot)\n",
    "\n",
    "    layout_column.css_classes.append('bk-container')\n",
    "    \n",
    "    json_ = json_item(layout_column, \"wikipedia-plot\")\n",
    "    \n",
    "    with open('embedabble_'+ dataset_title + '_picker.json', 'w') as outfile:\n",
    "        json.dump(json_, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_viz_timing(wikipedia_graph, wikipedia_grid_pos, extract_dates(wikipedia_df), 'wikipedia')\n",
    "create_viz_picker(wikipedia_graph, wikipedia_grid_pos, 'wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_viz_timing(meaned_graph_more3links, reddit_grid_pos, extract_dates(multiple_edges_meaned_data), 'reddit')\n",
    "create_viz_picker(meaned_graph_more3links, reddit_grid_pos, 'reddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
